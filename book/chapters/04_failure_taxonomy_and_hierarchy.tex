% ══════════════════════════════════════════════════════════════
%  Chapter 4 — Failure Taxonomy and Constructive Hierarchy
% ══════════════════════════════════════════════════════════════
\chapter{Failure Taxonomy and Constructive Hierarchy}\label{ch:taxonomy}

The absorbing-state theorem of \cref{ch:absorbing-states} gives a sharp
sufficient condition for greedy failure: when $\jdev < k$, no valid
sequence exists.  But the converse is false (\cref{rem:converse-false}).
When $\jdev \ge k$, the greedy policy may still fail---and it does so in
structurally distinct ways.  This chapter organises those failure modes
into a four-class taxonomy, shows that their fixes interact
antagonistically, and constructs a hierarchy of increasingly capable
algorithms that attack the failure classes in sequence.

We proceed as follows.  \Cref{sec:failure-classes} presents the taxonomy
(Classes~A--D) with a summary table and worked examples.
\Cref{sec:constraint-antagonism} documents the surprising result that
fixing one failure class can worsen another, establishing a partial order
among solvers.  \Cref{sec:constructive-hierarchy} lays out the full
algorithm hierarchy from myopic greedy to oracle.
\Cref{sec:tp-solver} details the TP-conditioned solver
(\cref{alg:tp-solver}) that occupies the practically important level of
the hierarchy.  \Cref{sec:failure-decomposition} derives the failure
decomposition formula that connects the taxonomy to the absorbing-state
theory.  \Cref{sec:approx-quality} analyses approximation quality,
confirming that the landscape is feasibility-dominated.
\Cref{sec:exercises-taxonomy} offers exercises.

% ──────────────────────────────────────────────────────────────
\section{Failure Classes}\label{sec:failure-classes}
% ──────────────────────────────────────────────────────────────

The empirical analysis of 138 greedy failures on bursty event-graph
instances reveals four structurally distinct failure mechanisms.  Each
class is defined by the stage of the pipeline at which the failure
manifests, the structural invariant that is violated, and the minimal
algorithmic intervention that repairs it.

\begin{table}[t]
\centering
\caption{Failure taxonomy for greedy narrative-arc construction.
         Prevalence figures refer to the bursty event-graph domain
         ($138$ greedy failures total).  Recovery rates are measured
         against the class-specific fix applied in isolation.}
\label{tab:failure-taxonomy}
\renewcommand{\arraystretch}{1.35}
\begin{tabular}{@{}clp{4.8cm}rlr@{}}
\toprule
\textbf{Class} & \textbf{Name} & \textbf{Mechanism} &
  \textbf{Prevalence} & \textbf{Fix} & \textbf{Recovery} \\
\midrule
A & Absorbing State &
  $\jdev < k$: turning point selected before enough
  development-eligible events exist.  Structural
  impossibility---no rearrangement can produce a valid sequence. &
  13.6\% & TP reassignment & --- \\[6pt]
B & Pipeline Coupling &
  Phase classifier misassigns labels.
  Position-based classification ignores the DFA state,
  mislabelling events that could serve as
  \textsc{development}. &
  45.7\% & Grammar-aware classifier & 100\% \\[6pt]
C & Commitment Timing &
  Greedy policy commits to bridge or span-critical
  events too early/late.  Wrong commitment window
  skips infrastructure events needed for temporal
  coverage. &
  13.0\% & TP-conditioned solver & 85--81\% \\[6pt]
D & Assembly Compression &
  Weight-maximising selection compresses phase
  structure.  High-weight events crowd into
  \textsc{resolution}, starving \textsc{development}. &
  41.3\% & Span-VAG with span filtering & 96.5\% \\
\bottomrule
\end{tabular}
\end{table}

\Cref{tab:failure-taxonomy} summarises the four classes.  We now examine
each in detail.

\subsection{Class A: Absorbing State Failures}\label{subsec:class-a}

Class~A failures are the domain of \cref{thm:prefix-impossibility}.
The mechanism is simple counting: the greedy policy selects a turning
point~$e^{*}$ that sits so early in the timeline---or, equivalently,
that has so few non-focal events preceding it---that the
development-eligible count $\jdev$ falls below the grammar's prefix
requirement~$k$.

\begin{example}[Class~A failure]\label{ex:class-a}
  Let $k = 3$ and suppose the turning point~$e^{*}$ occupies position
  $0.1$ on the normalised timeline (i.e., the first decile).  If only
  two non-focal events precede~$e^{*}$, then $\jdev = 2 < 3 = k$.  By
  \cref{thm:prefix-impossibility}, no valid sequence exists under this
  pivot assignment.  The product automaton enters an absorbing region
  from which no continuation can reach acceptance.

  The constructive fix is \emph{TP reassignment}: select a different
  focal event as the pivot---one that sits later in the timeline and
  affords $\jdev \ge k$.  This is the strategy employed by the
  TP-conditioned solver of \cref{sec:tp-solver}.
\end{example}

Class~A failures account for $13.6\%$ of bursty instances and represent
the hard boundary predicted by theory.  No algorithmic improvement to
the \emph{inner} solver can repair them; only a change of pivot (an
\emph{outer-loop} intervention) suffices.

\subsection{Class B: Pipeline Coupling Failures}\label{subsec:class-b}

Class~B failures arise not from the grammar itself but from the
\emph{classifier} that maps events to phase labels.  A position-based
classifier assigns labels based on an event's temporal position relative
to fixed thresholds (e.g., the first third of the timeline is
\textsc{setup}, the middle third is \textsc{development}).  This
classifier is blind to the DFA's current state: it may label an event as
\textsc{setup} even though the DFA has already transitioned to
$S_{\textsc{dev}}$ and would accept a \textsc{development} symbol.

\begin{example}[Class~B failure]\label{ex:class-b}
  Consider an event at normalised position $0.05$ in the timeline.  A
  position-based classifier labels it \textsc{setup} because it falls in
  the earliest segment.  However, the DFA has already consumed a
  \textsc{development} symbol (from a preceding event) and is in state
  $S_{\textsc{dev}}$.  A grammar-aware classifier would recognise this
  and correctly label the event as \textsc{development}, contributing to
  the prefix requirement.  The position-based classifier wastes a
  development opportunity, potentially pushing $\jdev$ below~$k$.
\end{example}

Class~B failures are the most prevalent single class, accounting for
$63$ of $138$ failures ($45.7\%$).  They are also the most cleanly
repairable: a grammar-aware classifier that tracks the DFA state
recovers $63/63$ ($100\%$) of Class~B failures.  This perfect recovery
rate reflects the fact that the underlying grammar structure is sound;
only the label assignment was wrong.

\subsection{Class C: Commitment Timing Failures}\label{subsec:class-c}

Class~C failures occur when the greedy policy's commitment order---the
sequence in which it irrevocably selects events---conflicts with the
structural requirements of the grammar.  The key scenario involves
\emph{bridge events}: events that span temporal gaps between clusters
(bursts) of activity.  These bridge events typically have low weight
(they are ``filler'' material, not high-salience focal events), so the
weight-maximising greedy policy skips them.  But without bridge events,
the selected set may violate \emph{span constraints}---requirements that
the narrative arc covers a minimum fraction of the simulation timeline.

\begin{example}[Class~C failure]\label{ex:class-c}
  A valid arc requires events spanning at least $15\%$ of the
  simulation timeline.  The greedy solver, maximising total weight,
  selects high-weight events clustered in a short interval
  (say, positions $0.40$--$0.55$, covering only $15\%$).  But the
  grammar also requires $k = 3$ development events before the turning
  point, and the highest-weight development candidates all fall in the
  same cluster.  The solver has committed to a dense, high-weight event
  set that satisfies the weight objective but violates the span
  constraint.

  A TP-conditioned solver that first fixes the turning point and then
  optimises subject to span requirements avoids this failure by
  selecting bridge events that maintain temporal coverage, even at a
  cost in total weight.
\end{example}

Class~C failures account for $18$ of $138$ failures ($13.0\%$).
Recovery rates across different constraint sets are $17/20$ ($85\%$) and
$21/26$ ($80.8\%$), reflecting the difficulty of balancing weight
maximisation against temporal coverage.

\subsection{Class D: Assembly Compression Failures}\label{subsec:class-d}

Class~D failures arise from a structural imbalance in the assembled
narrative arc.  The grammar is satisfied---the DFA accepts, and the
prefix requirement is met---but the phase structure is dramatically
lopsided.  Weight-maximising event selection concentrates high-weight
events in the \textsc{resolution} phase (post-turning-point), starving
the \textsc{development} phase of material.

\begin{example}[Class~D failure]\label{ex:class-d}
  Among $20$ selected events, $15$ have higher weight than the turning
  point and occur after it in the timeline.  Only $1$ event is assigned
  to \textsc{setup} and $2$ to \textsc{development}, barely meeting
  the prefix requirement of $k = 3$.  The grammar is technically
  satisfied, but the resulting arc is hollow: the narrative jumps almost
  immediately from setup to resolution with minimal development.

  Span-VAG (viability-aware greedy with span filtering) addresses this
  by filtering candidate events for span viability before weight
  maximisation.  Events that would compress the phase structure below a
  span threshold are excluded from the candidate pool.  Recovery rate:
  $55/57$ ($96.5\%$).
\end{example}

Class~D is the second most prevalent class at $57$ of $138$ failures
($41.3\%$), but it is also the most tractable: the span-VAG fix recovers
nearly all instances.

\begin{remark}[Failure classes are not mutually exclusive]%
\label{rem:overlap}
  A single failing instance may exhibit multiple failure classes
  simultaneously.  For example, a Class~B misclassification can reduce
  $\jdev$ to the point where a Class~A absorbing state is triggered.
  Similarly, the assembly compression of Class~D often co-occurs with
  the commitment timing issues of Class~C.  The prevalence figures in
  \cref{tab:failure-taxonomy} count each failure under its
  \emph{primary} class---the earliest stage at which a fix would have
  prevented the failure---and therefore sum to more than $100\%$ of
  unique failures.
\end{remark}

% ──────────────────────────────────────────────────────────────
\section{Constraint Antagonism}\label{sec:constraint-antagonism}
% ──────────────────────────────────────────────────────────────

The most surprising result in the failure analysis is not that different
algorithms fix different failure classes---that is expected.  The
surprise is that fixes for one class can \emph{worsen} another.

\paragraph{The Span-VAG paradox.}
Span-VAG achieves $62.7\%$ validity on bursty instances with gap
constraints, a substantial improvement over the myopic greedy baseline
of $54.7\%$.  Yet on \emph{multi-burst} instances with gap constraints,
Span-VAG achieves $0\%$ validity---strictly \emph{worse} than the
myopic greedy policy's $8\%$.

The mechanism is as follows.  Span viability favours selecting events at
burst endpoints to maximise temporal coverage of the narrative arc.  In
multi-burst topologies, temporal valleys separate the bursts.  The
low-weight bridge events in these valleys are essential for gap
feasibility: without them, the selected events have temporal gaps that
violate constraints.  But Span-VAG, by favouring endpoint events for
their span contribution, systematically skips these low-weight bridge
events.  The result is a selected set that has excellent span coverage
but catastrophic gap violations.

\paragraph{Partial order, not total order.}
This antagonism means that the algorithm hierarchy is a \emph{partial
order}, not a total order.  No single algorithm dominates across all
constraint combinations.  Span-VAG dominates greedy on bursty+gap but is
dominated by greedy on multi-burst+gap.  Gap-VAG dominates greedy on
both topologies but is incomparable with Span-VAG (better on
multi-burst+gap, different on bursty+gap).

\Cref{fig:partial-order} illustrates this partial order.  The directed
edges indicate strict dominance: algorithm~$X$ dominates algorithm~$Y$
if $X$ achieves weakly higher validity than $Y$ on every constraint
combination and strictly higher on at least one.  The key feature is the
pair of incomparable nodes---Span-VAG and Gap-VAG---which cannot be
ordered.  Both feed into BVAG (budget-aware VAG), which resolves the
antagonism by jointly optimising span and gap constraints.  The full
hierarchy culminates in the TP-Solver and, ultimately, the oracle.

\begin{figure}[t]
\centering
\begin{tikzpicture}[
    node distance=1.8cm and 2.8cm,
    every node/.style={
      draw,
      rounded corners=4pt,
      text width=2.6cm,
      minimum height=0.9cm,
      align=center,
      font=\small
    },
    arr/.style={
      -{Stealth[length=6pt]},
      thick,
      blue!60!black
    },
    incomp/.style={
      thick,
      red!60!black,
      dashed
    }
  ]

  % Level 0
  \node (greedy) {Myopic\\Greedy};

  % Level 1--2 (incomparable pair)
  \node (span) [above left=of greedy, yshift=0.5cm]
    {Span-VAG};
  \node (gap)  [above right=of greedy, yshift=0.5cm]
    {Gap-VAG};

  % Level 2.5
  \node (bvag) [above=3.2cm of greedy]
    {BVAG};

  % Level 3
  \node (tp)   [above=of bvag]
    {TP-Solver};

  % Level infinity
  \node (oracle) [above=of tp]
    {Oracle};

  % Dominance edges (upward = strictly better)
  \draw[arr] (greedy) -- (span);
  \draw[arr] (greedy) -- (gap);
  \draw[arr] (span)   -- (bvag);
  \draw[arr] (gap)    -- (bvag);
  \draw[arr] (bvag)   -- (tp);
  \draw[arr] (tp)     -- (oracle);

  % Incomparability indicator
  \draw[incomp] (span) -- node[draw=none, text width=1.8cm,
    fill=white, font=\scriptsize\itshape, minimum height=0pt]
    {incomparable} (gap);

\end{tikzpicture}
\caption{Partial order on solver algorithms.  Solid arrows indicate
         strict dominance (higher validity on every constraint
         combination).  The dashed line between Span-VAG and Gap-VAG
         indicates incomparability: neither dominates the other.  BVAG
         resolves the antagonism; the TP-Solver and Oracle complete the
         hierarchy.}
\label{fig:partial-order}
\end{figure}

% ──────────────────────────────────────────────────────────────
\section{The Constructive Hierarchy}\label{sec:constructive-hierarchy}
% ──────────────────────────────────────────────────────────────

\Cref{tab:hierarchy} presents the full algorithm hierarchy.  Each level
introduces one new capability that addresses a specific failure class (or
combination of classes) that the previous levels cannot handle.

\begin{table}[t]
\centering
\caption{Constructive algorithm hierarchy.  Validity rates are measured
         on the bursty+gap and multi-burst+gap constraint combinations.
         Complexity expressions use $n$ for pool size, $M$ for the
         number of TP candidates, $L$ for label-setting queue size,
         $d$ for DP state dimensions, $q$ for budget states, and $S$
         for the number of feasible subsets enumerated by the oracle.}
\label{tab:hierarchy}
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{@{}clp{3.4cm}cp{0.9cm}p{1.1cm}l@{}}
\toprule
\textbf{Level} & \textbf{Algorithm} & \textbf{Description} &
  \textbf{TP Selection} & \textbf{B+G} & \textbf{MB+G} &
  \textbf{Complexity} \\
\midrule
0   & Myopic Greedy & Weight-max, no lookahead &
  Endogenous & 54.7\% & 8\%   & $O(n^{2})$ \\[3pt]
1   & Span-VAG      & Viability filter on span &
  Endogenous & 62.7\% & 0\%   & $O(n^{2})$ \\[3pt]
2   & Gap-VAG       & Gap-aware viability &
  Endogenous & 81.3\% & 60\%  & $O(n^{2} \!\cdot\! \mathit{pool})$ \\[3pt]
2.5 & BVAG          & Budget-aware VAG &
  Endogenous & 82.0\% & 60\%  & $O(n^{2} \!\cdot\! q)$ \\[3pt]
3   & TP-Solver     & DP over TP candidates &
  Outer loop & 96.0\% & 94\%  & $O(M \!\cdot\! L \!\cdot\! n^{2} \!\cdot\! d)$ \\[3pt]
$\infty$ & Oracle   & Exhaustive enumeration &
  All focal  & 99.3\% & 100\% & $O(n^{2} \!\cdot\! S)$ \\
\bottomrule
\end{tabular}
\end{table}

We now describe each level, what it fixes, and what it cannot fix.

\paragraph{Level 0: Myopic Greedy.}
The baseline policy selects events in decreasing weight order, assigns
phase labels greedily, and picks the turning point endogenously as
$e^{*} = \argmax_{v : a(v) = a^{*}} w(v)$.  It has no lookahead and no
constraint awareness beyond the DFA itself.  It fails on all four
classes: Class~A by selecting a bad pivot, Class~B by using a
position-based classifier, Class~C by ignoring commitment timing, and
Class~D by concentrating weight in the post-TP region.

\paragraph{Level 1: Span-VAG.}
Adds a viability filter that excludes candidate events whose inclusion
would compress the arc's temporal span below a threshold.  This
addresses Class~D failures (assembly compression) by ensuring that the
selected events maintain adequate temporal coverage.  However, the span
filter can antagonise gap constraints, producing the $0\%$ validity on
multi-burst+gap documented in \cref{sec:constraint-antagonism}.

\paragraph{Level 2: Gap-VAG.}
Replaces the span-only viability filter with a gap-aware filter that
checks both span and maximum temporal gap constraints.  This resolves
the Span-VAG antagonism on multi-burst topologies, lifting validity from
$0\%$ to $60\%$ on multi-burst+gap.  Gap-VAG also improves on Span-VAG
for bursty+gap ($81.3\%$ vs.\ $62.7\%$), making it the first algorithm
in the hierarchy that is not dominated on any tested constraint
combination.

\paragraph{Level 2.5: BVAG (Budget-Aware VAG).}
Augments Gap-VAG with a budget constraint that limits the number of
events allocated to each phase.  This provides a marginal improvement
($82.0\%$ vs.\ $81.3\%$ on bursty+gap) by preventing extreme phase
imbalance.  The gains are modest because Gap-VAG already handles most
assembly compression; the budget constraint catches the residual cases.

\paragraph{Level 3: TP-Solver ($M = 25$).}
The first algorithm in the hierarchy to use an \emph{outer loop} over
turning-point candidates.  Instead of accepting the endogenous
$\argmax$ pivot, the TP-Solver considers the top-$M$ focal events by
weight and, for each candidate, solves the inner problem (find the best
valid event selection given a fixed TP) via label-setting dynamic
programming.  This outer loop directly attacks Class~A failures: if the
highest-weight pivot yields $\jdev < k$, the solver tries the next
candidate, and the next, until a feasible pivot is found.

The TP-Solver also mitigates Class~C failures because fixing the TP
\emph{Markovises} the inner problem: once the pivot is known, every
event's phase label is determined by its temporal relationship to the
fixed TP.  The inner problem reduces to a resource-constrained shortest
path problem (RCSPP), which the label-setting DP solves efficiently with
dominance pruning.  Details appear in \cref{sec:tp-solver}.

\paragraph{Level $\infty$: Oracle.}
The oracle enumerates all feasible subsets and selects the one with
maximum total weight.  It serves as the theoretical upper bound: any
valid sequence that exists will be found.  The oracle achieves $99.3\%$
validity on bursty+gap (the residual $0.7\%$ represents instances where
no valid sequence exists under any pivot assignment) and $100\%$ on
multi-burst+gap.

\begin{remark}[The oracle gap]\label{rem:oracle-gap}
  The gap between the TP-Solver ($96.0\%$) and the oracle ($99.3\%$)
  on bursty+gap is $3.3$ percentage points.  This gap represents
  instances where: (i)~the correct pivot is not among the top-$M = 25$
  candidates, or (ii)~the label-setting DP's dominance criterion
  prunes the optimal solution.  Increasing $M$ narrows the gap at the
  cost of linear growth in runtime.  The $94\%$--$100\%$ gap on
  multi-burst+gap has a similar origin.
\end{remark}

% ──────────────────────────────────────────────────────────────
\section{The TP-Conditioned Solver}\label{sec:tp-solver}
% ──────────────────────────────────────────────────────────────

The TP-conditioned solver is the practically important algorithm in the
hierarchy: it achieves near-oracle validity at polynomial cost.
\Cref{alg:tp-solver} presents the pseudocode; the remainder of this
section provides a line-by-line explanation.

\begin{algorithm}[t]
\caption{TP-Conditioned Solver}
\label{alg:tp-solver}
\begin{algorithmic}[1]
\Require Event pool $P$, prefix requirement $k$, candidate count $M$
\Ensure Best valid event selection, or $\varnothing$ if none found
\Statex
\Function{TP\_Solver}{$P,\, k,\, M$}
  \State $\mathit{candidates} \gets$
         top-$M$ focal events by weight from $P$
         \label{line:candidates}
  \State $\mathit{best\_solution} \gets \varnothing$;\quad
         $\mathit{best\_score} \gets -\infty$
         \label{line:init}
  \For{each candidate $c$ in $\mathit{candidates}$}
         \label{line:outer-loop}
    \State \Comment{Fix $c$ as \textsc{turning\_point}---this
           Markovises the inner problem}
           \label{line:fix-comment}
    \State $\mathit{solution} \gets
           \Call{LabelSettingDP}{P,\, c,\, k}$
           \label{line:inner-dp}
    \If{$\mathit{solution}$ is valid \textbf{and}
        $\Call{Score}{\mathit{solution}} > \mathit{best\_score}$}
           \label{line:check}
      \State $\mathit{best\_solution} \gets \mathit{solution}$
             \label{line:update-sol}
      \State $\mathit{best\_score} \gets
             \Call{Score}{\mathit{solution}}$
             \label{line:update-score}
    \EndIf
  \EndFor
  \State \Return $\mathit{best\_solution}$
         \label{line:return}
\EndFunction
\end{algorithmic}
\end{algorithm}

\paragraph{Line-by-line explanation.}

\begin{description}[leftmargin=2em, labelindent=0em, itemsep=4pt]
  \item[Line~\ref{line:candidates}: Candidate extraction.]
    The solver selects the top-$M$ focal events by weight as
    turning-point candidates.  This is the outer loop's search space.
    Setting $M = 25$ captures the vast majority of viable pivots: in
    practice, the correct pivot is almost always among the $25$
    highest-weight focal events.

  \item[Line~\ref{line:init}: Initialisation.]
    The best solution found so far is empty, with score $-\infty$.

  \item[Line~\ref{line:outer-loop}: Outer loop over candidates.]
    For each candidate~$c$, the solver fixes $c$ as the turning point
    and invokes the inner DP.  This is the key structural move: by
    fixing the TP, the solver eliminates the endogenous coupling that
    makes the full problem hard.

  \item[Line~\ref{line:fix-comment}: Markovisation.]
    Fixing $c$ as the turning point \emph{Markovises} the inner
    problem.  The reason is that, once the pivot is known, every
    event's phase label is determined by a simple rule: events before
    $c$ in the timeline are candidates for \textsc{setup} or
    \textsc{development}; $c$ itself is \textsc{turning\_point}; events
    after $c$ are candidates for \textsc{resolution}.  The phase
    classifier becomes \emph{deterministic}---no longer dependent on
    the DFA's state trajectory.  The inner problem therefore reduces to
    a Resource-Constrained Shortest Path Problem (RCSPP): find the
    weight-maximising subset of events that satisfies the grammar's
    prefix requirement ($\ge k$ development events before $c$) and any
    additional span or gap constraints.

  \item[Line~\ref{line:inner-dp}: Label-Setting DP.]
    The inner solver is a label-setting dynamic program that explores
    the state space of partial event selections.  Each state is a
    tuple encoding the current score, the number of phase slots used,
    and the earliest timestamp in the selection.  The DP propagates
    labels (partial solutions) forward through the event pool, pruning
    dominated labels at each step.

    The dominance criterion is: label $A$ dominates label $B$ if and
    only if
    \begin{enumerate}[label=(\roman*),itemsep=2pt]
      \item $A.\mathit{score} \ge B.\mathit{score}$,
      \item $A.\mathit{slots\_used} \le B.\mathit{slots\_used}$, and
      \item $A.\mathit{first\_time} \le B.\mathit{first\_time}$.
    \end{enumerate}
    This three-dimensional dominance criterion prunes the search space
    dramatically.  A label that is worse on score, uses more phase
    slots, and starts later in the timeline can never lead to a
    solution that the dominating label could not also produce.

  \item[Lines~\ref{line:check}--\ref{line:update-score}: Solution
    update.]
    If the inner DP returns a valid solution with a higher score than
    the current best, the solver updates its record.

  \item[Line~\ref{line:return}: Return.]
    After exhausting all $M$ candidates, the solver returns the best
    valid solution found, or $\varnothing$ if no candidate yielded a
    valid selection.
\end{description}

\begin{remark}[Why fixing the TP Markovises the problem]%
\label{rem:markovisation}
  Under the greedy policy, the phase label assigned to an event depends
  on the DFA's state at the moment the event is processed, which in
  turn depends on all previously assigned labels.  This creates a
  sequential dependency that prevents decomposition.

  Fixing the TP breaks this dependency.  With the pivot~$c$ known, the
  timeline splits into three regions: pre-$c$, the event $c$ itself,
  and post-$c$.  Events in the pre-$c$ region compete for
  \textsc{setup} and \textsc{development} slots; events in the post-$c$
  region are assigned \textsc{resolution}.  The assignment of labels in
  the pre-$c$ region is independent of the post-$c$ region (and vice
  versa), conditioned on the fixed TP.  This conditional independence is
  precisely the Markov property: the future (post-TP) is independent of
  the past (pre-TP) given the present (the TP itself).
\end{remark}

\begin{remark}[Complexity]\label{rem:tp-complexity}
  The outer loop runs $M$ iterations.  Each iteration invokes the
  label-setting DP, which processes $n$ events, maintaining a label set
  of size at most $L$ at each event.  Each label has $d$ state
  dimensions.  The total work is $O(M \cdot L \cdot n^{2} \cdot d)$.
  In practice, dominance pruning keeps $L$ small (typically
  $L \ll n$), and $d = 3$ (score, slots used, first time), making the
  algorithm efficient for event pools of moderate size.
\end{remark}

% ──────────────────────────────────────────────────────────────
\section{Failure Decomposition}\label{sec:failure-decomposition}
% ──────────────────────────────────────────────────────────────

The four-class taxonomy induces a natural decomposition of the overall
failure probability.

\begin{proposition}[Failure decomposition]\label{prop:failure-decomp}
  Let $P(\mathrm{fail})$ denote the probability that a greedy policy
  fails to produce a valid sequence.  Then
  \begin{equation}\label{eq:failure-decomp}
    P(\mathrm{fail})
    \;=\;
    P(\jdev < k)
    \;+\;
    \bigl[1 - P(\jdev < k)\bigr]
    \;\cdot\;
    P\!\bigl(\mathrm{other\_fail} \;\big|\; \jdev \ge k\bigr).
  \end{equation}
\end{proposition}

\begin{proof}
  The law of total probability, partitioning on whether the
  absorbing-state condition $\jdev < k$ holds, gives
  \begin{align*}
    P(\mathrm{fail})
    &= P(\mathrm{fail} \mid \jdev < k)\, P(\jdev < k)
     + P(\mathrm{fail} \mid \jdev \ge k)\, P(\jdev \ge k).
  \end{align*}
  By \cref{thm:prefix-impossibility},
  $P(\mathrm{fail} \mid \jdev < k) = 1$: every instance with $\jdev < k$
  fails.  Substituting and writing
  $P(\mathrm{other\_fail} \mid \jdev \ge k)$ for the residual failure
  rate yields \cref{eq:failure-decomp}.
\end{proof}

The decomposition has a clean algorithmic interpretation.  Each level of
the constructive hierarchy attacks a different term:

\begin{itemize}[itemsep=4pt]
  \item \textbf{First term: $P(\jdev < k)$.}  These are Class~A
    (absorbing state) failures.  They are predicted exactly by
    \cref{thm:prefix-impossibility} and can only be attacked by
    changing the pivot---the strategy of the TP-Solver's outer loop.

  \item \textbf{Second term: residual failures given $\jdev \ge k$.}
    These are Classes~B, C, and~D, conditional on escaping absorption.
    The grammar-aware classifier eliminates Class~B entirely.
    Span-VAG and Gap-VAG attack Class~D.  The TP-Solver's inner DP,
    by Markovising the label-assignment problem, attacks Class~C.
\end{itemize}

\begin{remark}[Bridge to the absorbing ideal]%
\label{rem:bridge-ideal}
  The first term in the failure decomposition is precisely the measure
  of the absorbing ideal of \cref{ch:absorbing-ideal}: $P(\jdev < k)$
  is the probability that the greedy policy produces a context element
  in the absorbing set $\absorb$.  The decomposition thus connects the
  algebraic theory (the ideal is inescapable under commitment) to the
  empirical hierarchy (the TP-Solver attacks the ideal by exploring
  alternative pivots).
\end{remark}

% ──────────────────────────────────────────────────────────────
\section{Approximation Quality}\label{sec:approx-quality}
% ──────────────────────────────────────────────────────────────

When a valid sequence exists and is found by the solver, how close is
its quality to the optimum?  The answer is: remarkably close.

\begin{table}[t]
\centering
\caption{Approximation quality ratios (solver score divided by oracle
         score) for instances where both solver and oracle find valid
         sequences.}
\label{tab:approx-quality}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Topology} & \textbf{Mean ratio} & \textbf{Minimum ratio} \\
\midrule
Bursty       & 0.996  & 0.975  \\
Multi-burst  & 0.9905 & 0.9512 \\
\bottomrule
\end{tabular}
\end{table}

\Cref{tab:approx-quality} reports the approximation quality ratios
(solver score divided by oracle score) for instances where both the
TP-Solver and the oracle find valid sequences.  On bursty topologies,
the mean ratio is $0.996$ with a worst case of $0.975$: the solver
typically achieves within $0.4\%$ of optimal, and never worse than
$2.5\%$.  On multi-burst topologies, the mean ratio is $0.9905$ with a
worst case of $0.9512$: within $1\%$ on average and within $5\%$ in the
worst case.

\begin{remark}[Feasibility-dominated landscape]%
\label{rem:feasibility-dominated}
  These near-optimal quality ratios reveal a fundamental feature of the
  problem landscape: it is \emph{feasibility-dominated}.  The primary
  challenge is finding \emph{any} valid solution, not optimising among
  many.  Once a valid solution exists, its quality is typically within
  $1$--$5\%$ of optimal.

  This observation justifies the focus on structural feasibility
  throughout the constructive hierarchy.  The hierarchy's levels are
  ordered by their ability to \emph{find valid solutions}, not by their
  ability to optimise among valid solutions.  The approximation quality
  data confirm that feasibility is the binding constraint: solve the
  feasibility problem, and the optimisation problem largely solves
  itself.
\end{remark}

\begin{remark}[Implications for algorithm design]%
\label{rem:design-implications}
  The feasibility-dominated landscape has a practical implication for
  algorithm design: it is more profitable to invest computational budget
  in exploring additional TP candidates (increasing~$M$) than in
  refining the inner solver's optimisation.  Each additional TP
  candidate opens a new region of the feasibility space; a better inner
  solver merely polishes the score within a region that has already been
  found.  The marginal value of an extra candidate exceeds the marginal
  value of a tighter approximation.
\end{remark}

% ──────────────────────────────────────────────────────────────
\section{Exercises}\label{sec:exercises-taxonomy}
% ──────────────────────────────────────────────────────────────

\begin{exercise}[Classifying failures]\label{exer:classify}
  Consider an event graph with $n = 15$, $k = 3$, and a greedy
  turning point $e^{*}$ at temporal position $0.6$ (normalised).  The
  greedy solver selects $12$ events, of which $9$ are in the post-TP
  region.  The grammar is satisfied, but the arc's temporal span covers
  only $20\%$ of the timeline.
  \begin{enumerate}[label=(\alph*)]
    \item Which failure class does this instance primarily belong to?
    \item Which secondary class may also apply?  Explain.
    \item Which level of the constructive hierarchy is the minimum
          required to fix this failure?
  \end{enumerate}

  \emph{Hint:} The grammar is satisfied (ruling out Class~A and~B),
  but the phase structure is lopsided (Class~D) and the temporal span
  is narrow (which may also indicate Class~C commitment timing issues).
\end{exercise}

\begin{exercise}[Antagonism construction]\label{exer:antagonism}
  Construct a concrete multi-burst event graph (with two bursts
  separated by a valley) in which:
  \begin{enumerate}[label=(\alph*)]
    \item Span-VAG selects events at the endpoints of each burst,
          achieving good span coverage but violating a gap constraint
          (maximum gap $\le 0.15$ of the timeline).
    \item Myopic greedy, by not filtering for span, happens to include
          a low-weight bridge event in the valley, satisfying the gap
          constraint.
  \end{enumerate}
  Verify that Span-VAG fails while greedy succeeds on this instance.
\end{exercise}

\begin{exercise}[Markovisation]\label{exer:markov}
  Let $P = \{e_1, \ldots, e_8\}$ be an event pool with $k = 2$.
  Suppose the greedy policy selects $e_3$ as the turning point.
  \begin{enumerate}[label=(\alph*)]
    \item Write down the three regions induced by fixing $e_3$ as the
          TP: which events are pre-TP, which is the TP, and which are
          post-TP?
    \item Explain why the label assignment in the pre-TP region is
          independent of the post-TP region, given the fixed TP.
    \item Suppose $e_5$ has a higher weight than $e_3$.  Under
          endogenous TP selection, $e_5$ would be the pivot.  Explain
          why the TP-Solver can still consider $e_3$ and why this is
          valuable.
  \end{enumerate}
\end{exercise}

\begin{exercise}[Failure decomposition with real numbers]%
\label{exer:decomp-numbers}
  In a domain where $P(\jdev < k) = 0.136$ (Class~A) and the residual
  failure rate given $\jdev \ge k$ is $P(\mathrm{other\_fail} \mid
  \jdev \ge k) = 0.52$:
  \begin{enumerate}[label=(\alph*)]
    \item Compute the overall failure probability using
          \cref{eq:failure-decomp}.
    \item A grammar-aware classifier eliminates all Class~B failures,
          reducing the residual failure rate to $0.12$.  Compute the
          new overall failure probability.
    \item The TP-Solver eliminates $90\%$ of Class~A failures (by
          finding alternative pivots).  If we also use the grammar-aware
          classifier, what is the overall failure probability?
  \end{enumerate}

  \emph{Solution sketch for (a):}
  $P(\mathrm{fail}) = 0.136 + (1 - 0.136) \cdot 0.52
   = 0.136 + 0.864 \cdot 0.52 = 0.136 + 0.449 = 0.585$.
\end{exercise}

\begin{exercise}[Oracle gap analysis]\label{exer:oracle-gap}
  The TP-Solver with $M = 25$ achieves $96.0\%$ validity on bursty+gap,
  while the oracle achieves $99.3\%$.  The gap is $3.3\%$.
  \begin{enumerate}[label=(\alph*)]
    \item If the correct pivot is uniformly distributed among all focal
          events and there are $50$ focal events, what is the
          probability that the correct pivot is \emph{not} among the
          top-$25$ by weight?  (Assume the correct pivot is equally
          likely to be any focal event.)
    \item In practice, the correct pivot is highly correlated with
          weight.  If $95\%$ of correct pivots are among the top-$25$ by
          weight, and the inner DP recovers $98\%$ of these, what
          validity rate does the model predict?
    \item How does this compare with the observed $96.0\%$?
  \end{enumerate}
\end{exercise}
