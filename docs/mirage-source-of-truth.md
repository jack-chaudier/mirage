# Mirage Source of Truth

This file is the canonical provenance map for model/run metadata in the Mirage artifacts.

## Resolution Rule

When docs conflict, use this precedence order:

1. Machine-readable run metadata (`adapter_config.json`, script defaults, generated CSV/JSON outputs).
2. Repro scripts that recreate those artifacts.
3. Narrative docs/README text.

## Canonical Run Families

| Run family | Canonical artifacts | Model/source of truth | Training unit semantics | Evaluation scope |
|---|---|---|---|---|
| Canonical HF/PEFT package (`mirage_aware_package.tar.gz` at repo root) | `mirage_aware_package.tar.gz::mirage_aware_adapter_balanced/adapter_config.json`, `mirage_aware_package.tar.gz::mirage_aware_adapter_balanced/checkpoint-250/trainer_state.json`, `mirage_aware_package.tar.gz::mirage_aware_adapter_balanced/training_args.bin`, `mirage_aware_package.tar.gz::mirage_aware_balanced_eval_summary.json` | `Qwen/Qwen2.5-7B-Instruct` | `num_train_epochs=1`, `per_device_train_batch_size=2`, `gradient_accumulation_steps=4`, `global_step=250` | 400-example eval slice (371 degraded, 29 strong); training config corresponds to ~2000 training examples |
| Alternate Qwen package lineage (Downloads) | `~/Downloads/mirage_aware_package.tar.gz::mirage_aware_adapter/adapter_config.json`, `~/Downloads/mirage_aware_package.tar.gz::mirage_aware_adapter/checkpoint-1200/trainer_state.json`, `~/Downloads/mirage_aware_package.tar.gz::mirage_aware_adapter/training_args.bin`, `~/Downloads/mirage_aware_package.tar.gz::mirage_aware_eval_summary.json` | `Qwen/Qwen2.5-7B-Instruct` | `num_train_epochs=3`, `per_device_train_batch_size=2`, `gradient_accumulation_steps=4`; checkpoint at `epoch=0.96`, `global_step=1200` | 400-example eval slice (371 degraded, 29 strong); schedule corresponds to ~10000 training examples |
| Released MLX adapter (`release/adapters/mirage_aware_v1`) | `endogenous_context_theory/release/adapters/mirage_aware_v1/adapter_config.json`, `endogenous_context_theory/scripts/train_mirage_aware.sh` | `mlx-community/gemma-2-2b-it-4bit` | `iters=600` (steps/iterations, not epochs) | `data/processed/valid.jsonl` generated by `generate_training_data.py` |
| Blackbox 5-model benchmark | `endogenous_context_theory/release/results/blackbox_bf16_5model/README.md` and model CSVs | Includes `Qwen 2.5 14B` (blackbox only) | Inference benchmark (no fine-tuning here) | MirageBench 12-task sweep |

## Claim Clarifications

- `Qwen 2.5 14B` is canonical for the blackbox benchmark run family, not for the released LoRA adapter lineage.
- For the canonical packaged LoRA artifact in this repo (`mirage_aware_package.tar.gz`), the base model is `Qwen/Qwen2.5-7B-Instruct` with rank `r=8`.
- For the canonical balanced package, metrics are: FT pivot accuracy (degraded) `368/371 = 99.19%`, FT silent mirage (degraded) `1/371 = 0.27%`, FT wrong overall `3/400 = 0.75%`.
- `0.27%` and `0.75%` are different denominators (degraded subset vs all rows); do not substitute one for the other.
- A blanket `3 epochs` claim is not universal: canonical balanced package has `num_train_epochs=1`; the alternate imbalanced package lineage carries `num_train_epochs=3`.
- `600 examples` is inconsistent with packaged training metadata: balanced package training config is ~2000 examples, and alternate imbalanced schedule is ~10000 examples.
- The released MLX adapter lineage remains valid as a separate run family (`mlx-community/gemma-2-2b-it-4bit`, `iters=600`, `r=8`).
- In Rhun retention sweeps, `n=200` means 200 events per trace (`n_events=200`), while sequence count is controlled by `--seeds` (default `100` in `run_context_retention_sweep.py`).
- The deterministic witness semantic loss uses `1 - 13/20 = 0.35` (`endogenous_context_theory/src/compression.py` + `tests/test_12_deterministic_witness.py`).
- The streaming organic trap aggregate `2306/4200 = 54.9%` corresponds to `7 epsilons x 3 k values x 200 seeds` in the streaming draft lineage.
- The NTSB silent-mirage aggregate `36/164 = 21.95%` is sourced from `endogenous_context_theory/results/ntsb/`.
- In the released KV-cache sweep table, 10% retention has `pivot_preserved = 0.0833` (8.3%, 1/12 tasks), not 0%.

## Package Variant Note

- Current repo-root package (`mirage_aware_package.tar.gz`) is the balanced 400-example Qwen package and extracts `mirage_aware_adapter_balanced/`.
- Current repo-root package checksum: `d09a254918d5ead13bd8440397c8ec793efd7b91c9cfa6e32a6312860cbed5e4`.
- The package is intentionally git-ignored (`*.tar.gz`) and distributed out-of-band (release attachment / external artifact host); verify integrity via checksum.
- Alternate imbalanced package (Downloads lineage) uses checkpoints around `1000/1100/1200` and reports `100.0%` FT pivot on the same 400-example eval slice.
