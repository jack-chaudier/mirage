Using Python: /Users/jackg/mirage/.venv/bin/python
=== Step 0: Install/verify dependencies ===
Requirement already satisfied: mlx-lm in ./.venv/lib/python3.14/site-packages (0.30.7)
Requirement already satisfied: numpy in ./.venv/lib/python3.14/site-packages (2.4.2)
Requirement already satisfied: pandas in ./.venv/lib/python3.14/site-packages (3.0.0)
Requirement already satisfied: requests in ./.venv/lib/python3.14/site-packages (2.32.5)
Requirement already satisfied: scipy in ./.venv/lib/python3.14/site-packages (1.17.0)
Requirement already satisfied: scikit-learn in ./.venv/lib/python3.14/site-packages (1.8.0)
Requirement already satisfied: tqdm in ./.venv/lib/python3.14/site-packages (4.67.3)
Requirement already satisfied: mlx>=0.30.4 in ./.venv/lib/python3.14/site-packages (from mlx-lm) (0.30.6)
Requirement already satisfied: transformers>=5.0.0 in ./.venv/lib/python3.14/site-packages (from mlx-lm) (5.2.0)
Requirement already satisfied: sentencepiece in ./.venv/lib/python3.14/site-packages (from mlx-lm) (0.2.1)
Requirement already satisfied: protobuf in ./.venv/lib/python3.14/site-packages (from mlx-lm) (6.33.5)
Requirement already satisfied: pyyaml in ./.venv/lib/python3.14/site-packages (from mlx-lm) (6.0.3)
Requirement already satisfied: jinja2 in ./.venv/lib/python3.14/site-packages (from mlx-lm) (3.1.6)
Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.14/site-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.14/site-packages (from requests) (3.4.4)
Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.14/site-packages (from requests) (3.11)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.14/site-packages (from requests) (2.6.3)
Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.14/site-packages (from requests) (2026.1.4)
Requirement already satisfied: joblib>=1.3.0 in ./.venv/lib/python3.14/site-packages (from scikit-learn) (1.5.3)
Requirement already satisfied: threadpoolctl>=3.2.0 in ./.venv/lib/python3.14/site-packages (from scikit-learn) (3.6.0)
Requirement already satisfied: mlx-metal==0.30.6 in ./.venv/lib/python3.14/site-packages (from mlx>=0.30.4->mlx-lm) (0.30.6)
Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)
Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in ./.venv/lib/python3.14/site-packages (from transformers>=5.0.0->mlx-lm) (1.4.1)
Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.14/site-packages (from transformers>=5.0.0->mlx-lm) (26.0)
Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.14/site-packages (from transformers>=5.0.0->mlx-lm) (2026.1.15)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.14/site-packages (from transformers>=5.0.0->mlx-lm) (0.22.2)
Requirement already satisfied: typer-slim in ./.venv/lib/python3.14/site-packages (from transformers>=5.0.0->mlx-lm) (0.24.0)
Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.14/site-packages (from transformers>=5.0.0->mlx-lm) (0.7.0)
Requirement already satisfied: filelock in ./.venv/lib/python3.14/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=5.0.0->mlx-lm) (3.24.2)
Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.14/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=5.0.0->mlx-lm) (2026.2.0)
Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.14/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=5.0.0->mlx-lm) (1.2.0)
Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.14/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=5.0.0->mlx-lm) (0.28.1)
Requirement already satisfied: shellingham in ./.venv/lib/python3.14/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=5.0.0->mlx-lm) (1.5.4)
Requirement already satisfied: typing-extensions>=4.1.0 in ./.venv/lib/python3.14/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=5.0.0->mlx-lm) (4.15.0)
Requirement already satisfied: anyio in ./.venv/lib/python3.14/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=5.0.0->mlx-lm) (4.12.1)
Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.14/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=5.0.0->mlx-lm) (1.0.9)
Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.14/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=5.0.0->mlx-lm) (0.16.0)
Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.14/site-packages (from jinja2->mlx-lm) (3.0.3)
Requirement already satisfied: typer>=0.24.0 in ./.venv/lib/python3.14/site-packages (from typer-slim->transformers>=5.0.0->mlx-lm) (0.24.0)
Requirement already satisfied: click>=8.2.1 in ./.venv/lib/python3.14/site-packages (from typer>=0.24.0->typer-slim->transformers>=5.0.0->mlx-lm) (8.3.1)
Requirement already satisfied: rich>=12.3.0 in ./.venv/lib/python3.14/site-packages (from typer>=0.24.0->typer-slim->transformers>=5.0.0->mlx-lm) (14.3.2)
Requirement already satisfied: annotated-doc>=0.0.2 in ./.venv/lib/python3.14/site-packages (from typer>=0.24.0->typer-slim->transformers>=5.0.0->mlx-lm) (0.0.4)
Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.14/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers>=5.0.0->mlx-lm) (4.0.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.14/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers>=5.0.0->mlx-lm) (2.19.2)
Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.14/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers>=5.0.0->mlx-lm) (0.1.2)
=== Step 0b: Verify MLX JSONL parser accepts extra metadata fields ===
MLX dataset preflight passed.
=== Step 1: Generate training data ===
Saved: /Users/jackg/mirage/endogenous_context_theory/training_data/train.jsonl
Saved: /Users/jackg/mirage/endogenous_context_theory/training_data/valid.jsonl
Saved: /Users/jackg/mirage/endogenous_context_theory/training_data/data_stats.json
Counts: train=1800 valid=200 total=2000
Expected examples: train=1800 valid=200
Label balance: train_degraded_rate=0.900 valid_degraded_rate=0.900
Warning: train split is not roughly balanced between STRONG and DEGRADED labels. This run keeps fixed 1 full + 9 compressed variants per task.

=== Sample training pairs ===

--- Example 1 ---
task_id=INV-medium-017 difficulty=medium full=True level=0.0 seed=0
oracle_pivot=B17-E056 degraded=False prereq_ratio=1.000
USER (truncated):
You are a precise analyst. Follow the scoring rule in the prompt exactly.

Investment Committee Timeline B17
The portfolio diary contains noisy market commentary and low-salience condition markers.
Interpretation rule: anchor analysis must follow the highest cumulative-return position.

[B17-E001] Week-01 | Position=NorthRiver Utilities Carry | WeeklyReturn=+0.28% | CumulativeReturn=0.28% | RegimeScore=2 | local checks passed with only minor variance in portfolio research, and includes procedural details that summarizers often collapse away. In local context it seems boring, but globally it changes which pivot is admissible.
[B17-E002] Week-02 | Position=Aurelia AI Semiconductor Basket | Wee...
ASSISTANT:
PIVOT_ID=B17-E056

Evidence assessment: STRONG
- Primary pivot B17-E056 present with 4/4 prerequisite events confirmed
- Confidence: HIGH

Prerequisite events:
- B17-E047: confirmed in context
- B17-E050: confirmed in context
- B17-E053: confirmed in context
- B17-E055: confirmed in context

Analysis: The selected pivot retains full prerequisite support in the provided timeline.

--- Example 2 ---
task_id=INV-medium-017 difficulty=medium full=False level=0.4 seed=101
oracle_pivot=B17-E056 degraded=True prereq_ratio=0.000
USER (truncated):
You are a precise analyst. Follow the scoring rule in the prompt exactly.

Investment Committee Timeline B17
The portfolio diary contains noisy market commentary and low-salience condition markers.
Interpretation rule: anchor analysis must follow the highest cumulative-return position.

[B17-E002] Week-02 | Position=Aurelia AI Semiconductor Basket | WeeklyReturn=+0.25% | CumulativeReturn=0.25% | RegimeScore=3 | local checks passed with only minor variance in portfolio research, and the note references dependencies that only matter when read with the full timeline. In local context it seems boring, but globally it changes which pivot is admissible.
[B17-E003] Week-03 | Position=Helios Grid In...
ASSISTANT:
PIVOT_ID=B17-E056

Evidence assessment: DEGRADED
- Primary candidate B17-E056 identified but 4/4 prerequisite events not found in context
- Alternative candidate B17-E068 also viable
- Confidence: LOW - evidence base appears incomplete

Prerequisite events:
- B17-E047: NOT FOUND in context
- B17-E050: NOT FOUND in context
- B17-E053: NOT FOUND in context
- B17-E055: NOT FOUND in context

Analysis: The context supports a salvage decision, but missing prerequisites reduce causal confidence.

--- Example 3 ---
task_id=INV-medium-017 difficulty=medium full=False level=0.4 seed=202
oracle_pivot=B17-E056 degraded=True prereq_ratio=0.000
USER (truncated):
You are a precise analyst. Follow the scoring rule in the prompt exactly.

Investment Committee Timeline B17
The portfolio diary contains noisy market commentary and low-salience condition markers.
Interpretation rule: anchor analysis must follow the highest cumulative-return position.

[B17-E001] Week-01 | Position=NorthRiver Utilities Carry | WeeklyReturn=+0.28% | CumulativeReturn=0.28% | RegimeScore=2 | local checks passed with only minor variance in portfolio research, and includes procedural details that summarizers often collapse away. In local context it seems boring, but globally it changes which pivot is admissible.
[B17-E004] Week-04 | Position=BlueHarbor Treasury Arbitrage | Weekl...
ASSISTANT:
PIVOT_ID=B17-E056

Evidence assessment: DEGRADED
- Primary candidate B17-E056 identified but 4/4 prerequisite events not found in context
- Alternative candidate B17-E068 also viable
- Confidence: LOW - evidence base appears incomplete

Prerequisite events:
- B17-E047: NOT FOUND in context
- B17-E050: NOT FOUND in context
- B17-E053: NOT FOUND in context
- B17-E055: NOT FOUND in context

Analysis: The context supports a salvage decision, but missing prerequisites reduce causal confidence.
=== Step 2: Fine-tune (primary: num_layers=8, iters=600) ===
Loading pretrained model
Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 22532.72it/s]
mx.metal.device_info is deprecated and will be removed in a future version. Use mx.device_info instead.
Loading datasets
Training
Trainable parameters: 0.122% (3.195M/2614.342M)
Starting training..., iters: 600
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:03<01:33,  3.88s/it]Calculating loss...:   8%|▊         | 2/25 [00:07<01:29,  3.87s/it]Calculating loss...:  12%|█▏        | 3/25 [00:11<01:24,  3.85s/it]Calculating loss...:  16%|█▌        | 4/25 [00:15<01:19,  3.79s/it]Calculating loss...:  20%|██        | 5/25 [00:19<01:15,  3.77s/it]Calculating loss...:  24%|██▍       | 6/25 [00:22<01:12,  3.82s/it]Calculating loss...:  28%|██▊       | 7/25 [00:26<01:09,  3.85s/it]Calculating loss...:  32%|███▏      | 8/25 [00:30<01:05,  3.84s/it]Calculating loss...:  36%|███▌      | 9/25 [00:34<01:01,  3.85s/it]Calculating loss...:  40%|████      | 10/25 [00:38<00:57,  3.82s/it]Calculating loss...:  44%|████▍     | 11/25 [00:42<00:53,  3.81s/it]Calculating loss...:  48%|████▊     | 12/25 [00:45<00:49,  3.79s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:49<00:45,  3.80s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:53<00:42,  3.86s/it]Calculating loss...:  60%|██████    | 15/25 [00:57<00:38,  3.81s/it]Calculating loss...:  64%|██████▍   | 16/25 [01:00<00:33,  3.76s/it]Calculating loss...:  68%|██████▊   | 17/25 [01:04<00:30,  3.76s/it]Calculating loss...:  72%|███████▏  | 18/25 [01:08<00:26,  3.74s/it]Calculating loss...:  76%|███████▌  | 19/25 [01:12<00:22,  3.75s/it]Calculating loss...:  80%|████████  | 20/25 [01:15<00:18,  3.73s/it]Calculating loss...:  84%|████████▍ | 21/25 [01:19<00:14,  3.70s/it]Calculating loss...:  88%|████████▊ | 22/25 [01:23<00:11,  3.75s/it]Calculating loss...:  92%|█████████▏| 23/25 [01:27<00:07,  3.80s/it]Calculating loss...:  96%|█████████▌| 24/25 [01:31<00:03,  3.77s/it]Calculating loss...: 100%|██████████| 25/25 [01:34<00:00,  3.79s/it]Calculating loss...: 100%|██████████| 25/25 [01:34<00:00,  3.79s/it]
Iter 1: Val loss 1.307, Val took 94.858s
