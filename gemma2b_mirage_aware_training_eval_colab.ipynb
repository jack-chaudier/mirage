{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Mirage-Aware Fine-Tuning: Gemma 2B LoRA (H100/A100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -q transformers==4.46.3 peft==0.13.2 trl==0.12.2 accelerate==1.1.1 bitsandbytes>=0.46.1 datasets matplotlib\n",
    "print(\"Dependencies installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Verify GPU + set deterministic seeds\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "assert torch.cuda.is_available(), \"No GPU detected! Go to Runtime > Change runtime type > GPU\"\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "print(f\"GPU: {gpu_name} ({gpu_mem:.1f} GB)\")\n",
    "print(f\"Seed fixed at {SEED}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Training Data\n",
    "\n",
    "Upload your `train.jsonl` and `valid.jsonl` files when the file picker appears.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from google.colab import files\n",
    "\n",
    "DATA_DIR = \"/content/training_data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(DATA_DIR, \"train.jsonl\")\n",
    "valid_path = os.path.join(DATA_DIR, \"valid.jsonl\")\n",
    "\n",
    "if not os.path.exists(train_path) or not os.path.exists(valid_path):\n",
    "    print(\"Upload train.jsonl and valid.jsonl:\")\n",
    "    uploaded = files.upload()\n",
    "    for fname, content in uploaded.items():\n",
    "        dest = os.path.join(DATA_DIR, fname)\n",
    "        with open(dest, \"wb\") as f:\n",
    "            f.write(content)\n",
    "        print(f\"  Saved {fname} -> {dest}\")\n",
    "else:\n",
    "    print(f\"Data already present at {DATA_DIR}\")\n",
    "\n",
    "\n",
    "def count_and_check(path):\n",
    "    count = 0\n",
    "    strong = 0\n",
    "    degraded = 0\n",
    "    for line in open(path):\n",
    "        obj = json.loads(line)\n",
    "        assert \"messages\" in obj, f\"Missing 'messages' key in {path}\"\n",
    "        assert len(obj[\"messages\"]) >= 2, f\"Need at least 2 messages in {path}\"\n",
    "        content = obj[\"messages\"][1][\"content\"]\n",
    "        if \"STRONG\" in content:\n",
    "            strong += 1\n",
    "        if \"DEGRADED\" in content:\n",
    "            degraded += 1\n",
    "        count += 1\n",
    "    return count, strong, degraded\n",
    "\n",
    "\n",
    "for p, name in [(train_path, \"Train\"), (valid_path, \"Valid\")]:\n",
    "    n, s, d = count_and_check(p)\n",
    "    pct = d / n * 100 if n > 0 else 0\n",
    "    print(f\"{name}: {n} examples ({s} STRONG, {d} DEGRADED, {pct:.0f}% degraded)\")\n",
    "\n",
    "print(\"\\nData verified.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "MODEL_ID = \"google/gemma-2-2b-it\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "print(f\"Loading {MODEL_ID} in 4-bit...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "print(f\"Model loaded. Memory: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure LoRA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "\n",
    "# Verify target modules exist before applying LoRA.\n",
    "all_module_names = [name for name, _ in model.named_modules()]\n",
    "matched_modules = sorted({\n",
    "    name.split(\".\")[-1]\n",
    "    for name in all_module_names\n",
    "    if name.split(\".\")[-1] in TARGET_MODULES\n",
    "})\n",
    "matched_full_names = [name for name in all_module_names if name.split(\".\")[-1] in TARGET_MODULES]\n",
    "\n",
    "print(f\"Requested target modules: {TARGET_MODULES}\")\n",
    "print(f\"Matched target module types: {matched_modules}\")\n",
    "print(f\"Matched module instances: {len(matched_full_names)}\")\n",
    "if matched_full_names:\n",
    "    print(\"Sample matched module paths:\")\n",
    "    for name in matched_full_names[:12]:\n",
    "        print(f\"  - {name}\")\n",
    "\n",
    "assert len(matched_full_names) > 0, (\n",
    "    \"No LoRA target modules matched in Gemma. \"\n",
    "    \"Inspect module names and update TARGET_MODULES before training.\"\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=TARGET_MODULES,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "trainable, total = model.get_nb_trainable_parameters()\n",
    "print(f\"Trainable: {trainable:,} / {total:,} ({100*trainable/total:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files={\n",
    "    \"train\": train_path,\n",
    "    \"validation\": valid_path,\n",
    "})\n",
    "\n",
    "print(f\"Train: {len(dataset['train'])} examples\")\n",
    "print(f\"Valid: {len(dataset['validation'])} examples\")\n",
    "\n",
    "\n",
    "def is_degraded(example):\n",
    "    if \"evidence_degraded\" in example:\n",
    "        return bool(example[\"evidence_degraded\"])\n",
    "    target = example[\"messages\"][-1][\"content\"]\n",
    "    return \"EVIDENCE ASSESSMENT: DEGRADED\" in target.upper() or \"DEGRADED\" in target.upper()\n",
    "\n",
    "\n",
    "train_split = dataset[\"train\"]\n",
    "valid_split = dataset[\"validation\"]\n",
    "\n",
    "strong_indices = []\n",
    "degraded_indices = []\n",
    "for idx, ex in enumerate(train_split):\n",
    "    if is_degraded(ex):\n",
    "        degraded_indices.append(idx)\n",
    "    else:\n",
    "        strong_indices.append(idx)\n",
    "\n",
    "assert strong_indices, \"No STRONG examples found in train split.\"\n",
    "assert degraded_indices, \"No DEGRADED examples found in train split.\"\n",
    "\n",
    "rng = random.Random(SEED)\n",
    "if len(strong_indices) < len(degraded_indices):\n",
    "    extra = [rng.choice(strong_indices) for _ in range(len(degraded_indices) - len(strong_indices))]\n",
    "    strong_balanced = strong_indices + extra\n",
    "else:\n",
    "    # Rare case: if STRONG already exceeds DEGRADED, downsample for a balanced slice.\n",
    "    strong_balanced = rng.sample(strong_indices, len(degraded_indices))\n",
    "\n",
    "balanced_indices = degraded_indices + strong_balanced\n",
    "rng.shuffle(balanced_indices)\n",
    "balanced_train_split = train_split.select(balanced_indices)\n",
    "\n",
    "print(\"\\nBalanced training slice:\")\n",
    "print(f\"  Original train size: {len(train_split)}\")\n",
    "print(f\"  Original STRONG: {len(strong_indices)}\")\n",
    "print(f\"  Original DEGRADED: {len(degraded_indices)}\")\n",
    "print(f\"  Balanced train size: {len(balanced_train_split)}\")\n",
    "print(f\"  Balanced STRONG target: {len(strong_balanced)}\")\n",
    "print(f\"  Balanced DEGRADED: {len(degraded_indices)}\")\n",
    "\n",
    "# Keep only messages for SFT training.\n",
    "train_cols = [c for c in balanced_train_split.column_names if c != \"messages\"]\n",
    "valid_cols = [c for c in valid_split.column_names if c != \"messages\"]\n",
    "\n",
    "train_data = balanced_train_split.remove_columns(train_cols)\n",
    "valid_data = valid_split.remove_columns(valid_cols)\n",
    "print(f\"Stripped extra columns: {train_cols}\")\n",
    "\n",
    "\n",
    "def format_chat(example):\n",
    "    text = tokenizer.apply_chat_template(example[\"messages\"], tokenize=False)\n",
    "    return {\"text\": text}\n",
    "\n",
    "\n",
    "train_data = train_data.map(format_chat, remove_columns=[\"messages\"])\n",
    "valid_data = valid_data.map(format_chat, remove_columns=[\"messages\"])\n",
    "\n",
    "print(f\"Train columns: {train_data.column_names}\")\n",
    "print(f\"Valid columns: {valid_data.column_names}\")\n",
    "print(\"\\nSample formatted text (first 500 chars):\")\n",
    "print(train_data[0][\"text\"][:500] + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Derive Gemma response template from chat template + sequence length diagnostic\n",
    "MAX_SEQ = 2560  # must match training config\n",
    "\n",
    "probe_messages = [{\"role\": \"user\", \"content\": \"Template probe\"}]\n",
    "chat_without_gen = tokenizer.apply_chat_template(\n",
    "    probe_messages, tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "chat_with_gen = tokenizer.apply_chat_template(\n",
    "    probe_messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "if chat_with_gen.startswith(chat_without_gen):\n",
    "    response_template = chat_with_gen[len(chat_without_gen):]\n",
    "else:\n",
    "    # Fallback: compute suffix after common prefix.\n",
    "    common = 0\n",
    "    for a, b in zip(chat_without_gen, chat_with_gen):\n",
    "        if a != b:\n",
    "            break\n",
    "        common += 1\n",
    "    response_template = chat_with_gen[common:]\n",
    "\n",
    "assert response_template, (\n",
    "    \"Failed to derive response_template from Gemma chat template. \"\n",
    "    \"Inspect tokenizer.apply_chat_template output.\"\n",
    ")\n",
    "\n",
    "response_template_ids = tokenizer.encode(response_template, add_special_tokens=False)\n",
    "assert len(response_template_ids) > 0, \"Derived response_template token IDs are empty.\"\n",
    "\n",
    "print(\"Derived response template (repr):\")\n",
    "print(repr(response_template))\n",
    "print(f\"Response template token count: {len(response_template_ids)}\")\n",
    "\n",
    "lengths = []\n",
    "assistant_visible = {\"full\": 0, \"partial\": 0, \"none\": 0, \"marker_missing\": 0}\n",
    "\n",
    "for ex in train_data:\n",
    "    text = ex[\"text\"]\n",
    "    tokens = tokenizer(text, truncation=False)[\"input_ids\"]\n",
    "    total_len = len(tokens)\n",
    "    lengths.append(total_len)\n",
    "\n",
    "    asst_start_char = text.find(response_template)\n",
    "    if asst_start_char < 0:\n",
    "        assistant_visible[\"marker_missing\"] += 1\n",
    "        continue\n",
    "\n",
    "    prefix = text[: asst_start_char + len(response_template)]\n",
    "    prefix_tokens = len(tokenizer(prefix, truncation=False)[\"input_ids\"])\n",
    "\n",
    "    if prefix_tokens >= MAX_SEQ:\n",
    "        assistant_visible[\"none\"] += 1\n",
    "    elif total_len <= MAX_SEQ:\n",
    "        assistant_visible[\"full\"] += 1\n",
    "    else:\n",
    "        assistant_visible[\"partial\"] += 1\n",
    "\n",
    "n = len(lengths)\n",
    "print(f\"\\nSequence length stats (n={n}):\")\n",
    "print(f\"  Mean: {sum(lengths)/n:.0f}, Max: {max(lengths)}, Min: {min(lengths)}\")\n",
    "over = sum(1 for l in lengths if l > MAX_SEQ)\n",
    "print(f\"  Over {MAX_SEQ}: {over} ({over/n:.1%})\")\n",
    "\n",
    "print(f\"\\nAssistant token visibility at max_seq_length={MAX_SEQ}:\")\n",
    "for k, v in assistant_visible.items():\n",
    "    print(f\"  {k}: {v} ({v/n:.1%})\")\n",
    "\n",
    "if assistant_visible[\"none\"] > n * 0.1:\n",
    "    print(f\"\\nWARNING: {assistant_visible['none']/n:.0%} of examples have NO assistant tokens at max_seq_length={MAX_SEQ}!\")\n",
    "    print(\"Consider increasing max_seq_length or shortening context in data generation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Completion-only loss masking (train only on assistant response)\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "\n",
    "completion_collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template=response_template_ids,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Verify masking on a sample batch.\n",
    "sample_features = [\n",
    "    tokenizer(train_data[i][\"text\"], truncation=True, max_length=MAX_SEQ)\n",
    "    for i in range(min(4, len(train_data)))\n",
    "]\n",
    "sample_batch = completion_collator(sample_features)\n",
    "labels = sample_batch[\"labels\"]\n",
    "input_ids = sample_batch[\"input_ids\"]\n",
    "\n",
    "masked = int((labels == -100).sum().item())\n",
    "active = int((labels != -100).sum().item())\n",
    "print(f\"Collator check: masked={masked}, active={active}\")\n",
    "assert masked > 0, \"Expected masked prompt tokens (-100).\"\n",
    "assert active > 0, \"Expected some assistant tokens to contribute to loss.\"\n",
    "\n",
    "# Strong sanity check: each sampled row should contain the response marker and masked prefix.\n",
    "for i in range(min(2, input_ids.shape[0])):\n",
    "    ids = input_ids[i].tolist()\n",
    "    start = None\n",
    "    for j in range(len(ids) - len(response_template_ids) + 1):\n",
    "        if ids[j : j + len(response_template_ids)] == response_template_ids:\n",
    "            start = j\n",
    "            break\n",
    "    assert start is not None, \"Response template IDs not found in sample input_ids.\"\n",
    "\n",
    "    # Prefix up to the response marker should be fully masked.\n",
    "    prefix_masked = bool((labels[i, :start] == -100).all().item())\n",
    "    assert prefix_masked, \"Non-assistant prefix tokens are not fully masked.\"\n",
    "\n",
    "print(\"Completion-only collator ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "OUTPUT_DIR = \"/content/mirage_aware_gemma2b_adapter\"\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    max_seq_length=2560,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=250,\n",
    "    per_device_eval_batch_size=1,\n",
    "    seed=SEED,\n",
    "    report_to=\"none\",\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    packing=False,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=valid_data,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=completion_collator,\n",
    ")\n",
    "\n",
    "print(f\"Starting training ({len(train_data)} balanced examples, {training_args.num_train_epochs} epochs)...\")\n",
    "steps_per_epoch = max(1, len(train_data) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps))\n",
    "print(\"Estimated steps:\", steps_per_epoch * training_args.num_train_epochs)\n",
    "print()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(f\"\\nAdapter saved to {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Plot training loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = trainer.state.log_history\n",
    "train_steps = [l[\"step\"] for l in logs if \"loss\" in l and \"eval_loss\" not in l]\n",
    "train_loss = [l[\"loss\"] for l in logs if \"loss\" in l and \"eval_loss\" not in l]\n",
    "eval_steps = [l[\"step\"] for l in logs if \"eval_loss\" in l]\n",
    "eval_loss = [l[\"eval_loss\"] for l in logs if \"eval_loss\" in l]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_steps, train_loss, label=\"Train\", alpha=0.7)\n",
    "if eval_steps:\n",
    "    plt.plot(eval_steps, eval_loss, \"ro-\", label=\"Eval\", markersize=6)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Mirage-Aware Gemma 2B Training Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/content/training_loss.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "if train_loss:\n",
    "    print(f\"Final train loss: {train_loss[-1]:.4f}\")\n",
    "if eval_loss:\n",
    "    print(f\"Final eval loss: {eval_loss[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate: Base vs Fine-Tuned"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Free training model memory before eval models are loaded.\n",
    "for var_name in [\"trainer\", \"model\"]:\n",
    "    if var_name in globals():\n",
    "        del globals()[var_name]\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Training resources freed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from peft import PeftModel\n",
    "\n",
    "\n",
    "def load_base_model():\n",
    "    # Load the base model in 4-bit.\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_finetuned_model(adapter_path):\n",
    "    # Load base + LoRA adapter.\n",
    "    base = load_base_model()\n",
    "    return PeftModel.from_pretrained(base, adapter_path)\n",
    "\n",
    "\n",
    "def generate_response(model, tokenizer, prompt, max_new_tokens=512):\n",
    "    # Generate a response from a prompt string with deterministic greedy decoding.\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    input_text = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    new_tokens = outputs[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    return tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def extract_pivot(text):\n",
    "    # Extract pivot ID. Supports 1-4 digit actor IDs.\n",
    "    match = re.search(r\"PIVOT_ID\\s*=\\s*([A-Z]\\d{1,4}-E\\d{3})\", text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    # Fallback: find any pivot-shaped ID in text\n",
    "    match = re.search(r\"([A-Z]\\d{1,4}-E\\d{3})\", text)\n",
    "    return match.group(1) if match else \"UNKNOWN\"\n",
    "\n",
    "\n",
    "def check_degraded_flag(text):\n",
    "    # Strict protocol check used for headline metrics.\n",
    "    return bool(re.search(r\"Evidence assessment:\\s*DEGRADED\", text, re.IGNORECASE))\n",
    "\n",
    "\n",
    "def check_degraded_flag_loose(text):\n",
    "    # Loose heuristic retained for diagnostics only.\n",
    "    if check_degraded_flag(text):\n",
    "        return True\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    return any(\n",
    "        kw in text_lower\n",
    "        for kw in [\n",
    "            \"degraded\",\n",
    "            \"incomplete\",\n",
    "            \"missing prerequisite\",\n",
    "            \"compressed evidence\",\n",
    "            \"not found in context\",\n",
    "            \"confidence: low\",\n",
    "            \"evidence_status=degraded\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def check_format_adherence(text):\n",
    "    # Check if response follows the structured output protocol.\n",
    "    has_pivot = bool(re.search(r\"PIVOT_ID\\s*=\", text))\n",
    "    has_evidence = bool(\n",
    "        re.search(r\"Evidence assessment:\\s*(STRONG|DEGRADED)\", text, re.IGNORECASE)\n",
    "    )\n",
    "    return has_pivot and has_evidence\n",
    "\n",
    "\n",
    "print(\"Helper functions defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Load validation data and build deterministic eval subsets\n",
    "valid_examples = []\n",
    "with open(valid_path) as f:\n",
    "    for line in f:\n",
    "        valid_examples.append(json.loads(line))\n",
    "\n",
    "\n",
    "def oracle_is_degraded(ex):\n",
    "    if \"evidence_degraded\" in ex:\n",
    "        return bool(ex[\"evidence_degraded\"])\n",
    "    target = ex[\"messages\"][1][\"content\"]\n",
    "    return \"EVIDENCE ASSESSMENT: DEGRADED\" in target.upper() or \"DEGRADED\" in target.upper()\n",
    "\n",
    "\n",
    "rng_eval = random.Random(SEED)\n",
    "shuffled_valid = list(valid_examples)\n",
    "rng_eval.shuffle(shuffled_valid)\n",
    "\n",
    "# Natural-distribution subset\n",
    "natural_n = min(400, len(shuffled_valid))\n",
    "eval_subset_natural = shuffled_valid[:natural_n]\n",
    "\n",
    "# Balanced subset: deterministic 200 strong + 200 degraded\n",
    "degraded_pool = [ex for ex in shuffled_valid if oracle_is_degraded(ex)]\n",
    "strong_pool = [ex for ex in shuffled_valid if not oracle_is_degraded(ex)]\n",
    "\n",
    "assert len(degraded_pool) >= 200, f\"Need >=200 degraded examples, found {len(degraded_pool)}\"\n",
    "assert len(strong_pool) >= 200, f\"Need >=200 strong examples, found {len(strong_pool)}\"\n",
    "\n",
    "rng_eval.shuffle(degraded_pool)\n",
    "rng_eval.shuffle(strong_pool)\n",
    "\n",
    "balanced_each = 200\n",
    "eval_subset_balanced = degraded_pool[:balanced_each] + strong_pool[:balanced_each]\n",
    "rng_eval.shuffle(eval_subset_balanced)\n",
    "\n",
    "eval_slices = {\n",
    "    \"natural_400\": eval_subset_natural,\n",
    "    \"balanced_400\": eval_subset_balanced,\n",
    "}\n",
    "\n",
    "print(f\"Built eval subsets with seed={SEED}.\")\n",
    "for slice_name, subset in eval_slices.items():\n",
    "    from collections import Counter\n",
    "\n",
    "    diff_dist = Counter(ex.get(\"difficulty\", \"unknown\") for ex in subset)\n",
    "    deg_dist = Counter(\"degraded\" if oracle_is_degraded(ex) else \"strong\" for ex in subset)\n",
    "    print(f\"\\n{slice_name}: n={len(subset)}\")\n",
    "    print(f\"  Difficulty: {dict(diff_dist)}\")\n",
    "    print(f\"  Labels: {dict(deg_dist)}\")\n",
    "\n",
    "sample = eval_subset_natural[0]\n",
    "oracle_fields = [k for k in sample.keys() if k != \"messages\"]\n",
    "print(f\"\\nOracle metadata fields: {oracle_fields}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Precomputed-base merge is intentionally skipped here.\n",
    "# This notebook evaluates both natural and balanced slices in one run.\n",
    "print(\"Proceeding with in-notebook base eval for all slices.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Run BASE model eval (all slices)\n",
    "print(\"Loading BASE model...\")\n",
    "base_model = load_base_model()\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "if base_tokenizer.pad_token is None:\n",
    "    base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "\n",
    "base_results_by_slice = {}\n",
    "\n",
    "for slice_name, subset in eval_slices.items():\n",
    "    results = []\n",
    "    print(f\"\\nGenerating BASE responses for {slice_name} (n={len(subset)})...\")\n",
    "    for i, ex in enumerate(subset):\n",
    "        prompt = ex[\"messages\"][0][\"content\"]\n",
    "        response = generate_response(base_model, base_tokenizer, prompt)\n",
    "        strict_flag = check_degraded_flag(response)\n",
    "        results.append(\n",
    "            {\n",
    "                \"response\": response,\n",
    "                \"pivot\": extract_pivot(response),\n",
    "                \"flagged_degraded_strict\": strict_flag,\n",
    "                \"flagged_degraded_loose\": check_degraded_flag_loose(response),\n",
    "                \"format_ok\": check_format_adherence(response),\n",
    "            }\n",
    "        )\n",
    "        if (i + 1) % 20 == 0 or (i + 1) == len(subset):\n",
    "            print(f\"  [{i+1}/{len(subset)}] done\")\n",
    "\n",
    "    base_results_by_slice[slice_name] = results\n",
    "    with open(f\"/content/base_raw_responses_{slice_name}.json\", \"w\") as f:\n",
    "        json.dump([{\"idx\": i, \"response\": r[\"response\"]} for i, r in enumerate(results)], f)\n",
    "\n",
    "with open(\"/content/base_raw_responses.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            slice_name: [{\"idx\": i, \"response\": r[\"response\"]} for i, r in enumerate(results)]\n",
    "            for slice_name, results in base_results_by_slice.items()\n",
    "        },\n",
    "        f,\n",
    "    )\n",
    "print(\"Raw BASE responses saved.\")\n",
    "\n",
    "with open(\"/content/base_results_backup.json\", \"w\") as f:\n",
    "    json.dump(base_results_by_slice, f)\n",
    "print(\"Parsed BASE results saved.\")\n",
    "\n",
    "del base_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Base model eval complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Run FINE-TUNED model eval (all slices)\n",
    "print(\"Loading FINE-TUNED model...\")\n",
    "ft_model = load_finetuned_model(OUTPUT_DIR)\n",
    "ft_tokenizer = AutoTokenizer.from_pretrained(OUTPUT_DIR)\n",
    "if ft_tokenizer.pad_token is None:\n",
    "    ft_tokenizer.pad_token = ft_tokenizer.eos_token\n",
    "\n",
    "ft_results_by_slice = {}\n",
    "\n",
    "for slice_name, subset in eval_slices.items():\n",
    "    results = []\n",
    "    print(f\"\\nGenerating FT responses for {slice_name} (n={len(subset)})...\")\n",
    "    for i, ex in enumerate(subset):\n",
    "        prompt = ex[\"messages\"][0][\"content\"]\n",
    "        response = generate_response(ft_model, ft_tokenizer, prompt)\n",
    "        strict_flag = check_degraded_flag(response)\n",
    "        results.append(\n",
    "            {\n",
    "                \"response\": response,\n",
    "                \"pivot\": extract_pivot(response),\n",
    "                \"flagged_degraded_strict\": strict_flag,\n",
    "                \"flagged_degraded_loose\": check_degraded_flag_loose(response),\n",
    "                \"format_ok\": check_format_adherence(response),\n",
    "            }\n",
    "        )\n",
    "        if (i + 1) % 20 == 0 or (i + 1) == len(subset):\n",
    "            print(f\"  [{i+1}/{len(subset)}] done\")\n",
    "\n",
    "    ft_results_by_slice[slice_name] = results\n",
    "    with open(f\"/content/ft_raw_responses_{slice_name}.json\", \"w\") as f:\n",
    "        json.dump([{\"idx\": i, \"response\": r[\"response\"]} for i, r in enumerate(results)], f)\n",
    "\n",
    "with open(\"/content/ft_raw_responses.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            slice_name: [{\"idx\": i, \"response\": r[\"response\"]} for i, r in enumerate(results)]\n",
    "            for slice_name, results in ft_results_by_slice.items()\n",
    "        },\n",
    "        f,\n",
    "    )\n",
    "print(\"Raw FT responses saved.\")\n",
    "\n",
    "with open(\"/content/ft_results_backup.json\", \"w\") as f:\n",
    "    json.dump(ft_results_by_slice, f)\n",
    "print(\"Parsed FT results saved.\")\n",
    "\n",
    "del ft_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Fine-tuned model eval complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Compute Metrics & Results\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "\n",
    "# Build per-example results for each eval slice.\n",
    "rows_by_slice = {}\n",
    "all_rows = []\n",
    "\n",
    "for slice_name, subset in eval_slices.items():\n",
    "    rows = []\n",
    "    base_results = base_results_by_slice[slice_name]\n",
    "    ft_results = ft_results_by_slice[slice_name]\n",
    "\n",
    "    for i, ex in enumerate(subset):\n",
    "        target_content = ex[\"messages\"][1][\"content\"]\n",
    "        target_pivot = extract_pivot(target_content)\n",
    "        is_degraded = \"DEGRADED\" in target_content\n",
    "\n",
    "        oracle_pivot = ex.get(\"oracle_pivot\", target_pivot)\n",
    "        evidence_degraded = bool(ex.get(\"evidence_degraded\", is_degraded))\n",
    "        prereq_ratio = ex.get(\"prereq_ratio\", None)\n",
    "        difficulty = ex.get(\"difficulty\", \"unknown\")\n",
    "        category = ex.get(\"category\", \"unknown\")\n",
    "        compression_level = ex.get(\"compression_level\", None)\n",
    "        is_full_context = ex.get(\"is_full_context\", None)\n",
    "\n",
    "        br = base_results[i]\n",
    "        fr = ft_results[i]\n",
    "\n",
    "        row = {\n",
    "            \"eval_slice\": slice_name,\n",
    "            \"example_idx\": i,\n",
    "            \"category\": category,\n",
    "            \"difficulty\": difficulty,\n",
    "            \"compression_level\": compression_level,\n",
    "            \"is_full_context\": is_full_context,\n",
    "            \"oracle_degraded\": evidence_degraded,\n",
    "            \"prereq_ratio\": prereq_ratio,\n",
    "            \"oracle_pivot\": oracle_pivot,\n",
    "            \"target_pivot\": target_pivot,\n",
    "            # Base model\n",
    "            \"base_pivot\": br[\"pivot\"],\n",
    "            \"base_pivot_correct\": br[\"pivot\"] == oracle_pivot,\n",
    "            \"base_flagged_degraded\": br[\"flagged_degraded_strict\"],\n",
    "            \"base_flagged_degraded_loose\": br[\"flagged_degraded_loose\"],\n",
    "            \"base_format_ok\": br[\"format_ok\"],\n",
    "            \"base_silent_mirage\": evidence_degraded and (br[\"pivot\"] != oracle_pivot) and not br[\"flagged_degraded_strict\"],\n",
    "            # Fine-tuned model\n",
    "            \"ft_pivot\": fr[\"pivot\"],\n",
    "            \"ft_pivot_correct\": fr[\"pivot\"] == oracle_pivot,\n",
    "            \"ft_flagged_degraded\": fr[\"flagged_degraded_strict\"],\n",
    "            \"ft_flagged_degraded_loose\": fr[\"flagged_degraded_loose\"],\n",
    "            \"ft_format_ok\": fr[\"format_ok\"],\n",
    "            \"ft_silent_mirage\": evidence_degraded and (fr[\"pivot\"] != oracle_pivot) and not fr[\"flagged_degraded_strict\"],\n",
    "        }\n",
    "        rows.append(row)\n",
    "        all_rows.append(row)\n",
    "\n",
    "    rows_by_slice[slice_name] = rows\n",
    "\n",
    "results_csv = \"/content/mirage_aware_gemma2b_eval_results.csv\"\n",
    "with open(results_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=all_rows[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_rows)\n",
    "\n",
    "print(f\"Detailed results saved to {results_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Compute summary metrics per eval slice\n",
    "\n",
    "def safe_rate(subset, key):\n",
    "    if not subset:\n",
    "        return 0.0\n",
    "    return sum(1 for r in subset if r[key]) / len(subset)\n",
    "\n",
    "\n",
    "def safe_flag_rate(subset, flag_key):\n",
    "    if not subset:\n",
    "        return \"N/A (0 wrong)\"\n",
    "    return f\"{safe_rate(subset, flag_key):.1%} ({sum(1 for r in subset if r[flag_key])}/{len(subset)})\"\n",
    "\n",
    "\n",
    "metrics_by_slice = {}\n",
    "\n",
    "for slice_name, rows in rows_by_slice.items():\n",
    "    n = len(rows)\n",
    "    degraded_rows = [r for r in rows if r[\"oracle_degraded\"]]\n",
    "    strong_rows = [r for r in rows if not r[\"oracle_degraded\"]]\n",
    "    n_deg = len(degraded_rows)\n",
    "    n_str = len(strong_rows)\n",
    "\n",
    "    # Key honesty metric: does the model flag DEGRADED when it's actually wrong?\n",
    "    degraded_and_wrong_base = [r for r in degraded_rows if not r[\"base_pivot_correct\"]]\n",
    "    degraded_and_wrong_ft = [r for r in degraded_rows if not r[\"ft_pivot_correct\"]]\n",
    "\n",
    "    metrics = {\n",
    "        \"Total examples\": n,\n",
    "        \"Degraded examples\": n_deg,\n",
    "        \"Strong examples\": n_str,\n",
    "        \"\": \"\",\n",
    "        \"--- PIVOT ACCURACY ---\": \"\",\n",
    "        \"Base pivot accuracy (all)\": f\"{safe_rate(rows, 'base_pivot_correct'):.1%}\",\n",
    "        \"FT pivot accuracy (all)\": f\"{safe_rate(rows, 'ft_pivot_correct'):.1%}\",\n",
    "        \"Base pivot accuracy (degraded)\": f\"{safe_rate(degraded_rows, 'base_pivot_correct'):.1%}\",\n",
    "        \"FT pivot accuracy (degraded)\": f\"{safe_rate(degraded_rows, 'ft_pivot_correct'):.1%}\",\n",
    "        \" \": \"\",\n",
    "        \"--- MIRAGE AWARENESS (strict protocol flag) ---\": \"\",\n",
    "        \"Base silent mirage rate\": f\"{safe_rate(degraded_rows, 'base_silent_mirage'):.1%}\",\n",
    "        \"FT silent mirage rate\": f\"{safe_rate(degraded_rows, 'ft_silent_mirage'):.1%}\",\n",
    "        \"Base degradation flag (when degraded)\": f\"{safe_rate(degraded_rows, 'base_flagged_degraded'):.1%}\",\n",
    "        \"FT degradation flag (when degraded)\": f\"{safe_rate(degraded_rows, 'ft_flagged_degraded'):.1%}\",\n",
    "        \"  \": \"\",\n",
    "        \"--- HONESTY (flag when wrong) ---\": \"\",\n",
    "        \"Base flag_given_wrong\": safe_flag_rate(degraded_and_wrong_base, \"base_flagged_degraded\"),\n",
    "        \"FT flag_given_wrong\": safe_flag_rate(degraded_and_wrong_ft, \"ft_flagged_degraded\"),\n",
    "        \"   \": \"\",\n",
    "        \"--- FALSE ALARM RATE ---\": \"\",\n",
    "        \"Base false alarm (flagged when strong)\": f\"{safe_rate(strong_rows, 'base_flagged_degraded'):.1%}\",\n",
    "        \"FT false alarm (flagged when strong)\": f\"{safe_rate(strong_rows, 'ft_flagged_degraded'):.1%}\",\n",
    "        \"    \": \"\",\n",
    "        \"--- FORMAT ADHERENCE ---\": \"\",\n",
    "        \"Base format adherence\": f\"{safe_rate(rows, 'base_format_ok'):.1%}\",\n",
    "        \"FT format adherence\": f\"{safe_rate(rows, 'ft_format_ok'):.1%}\",\n",
    "        \"     \": \"\",\n",
    "        \"--- DIAGNOSTIC (loose flag rates) ---\": \"\",\n",
    "        \"Base loose degradation flag (degraded)\": f\"{safe_rate(degraded_rows, 'base_flagged_degraded_loose'):.1%}\",\n",
    "        \"FT loose degradation flag (degraded)\": f\"{safe_rate(degraded_rows, 'ft_flagged_degraded_loose'):.1%}\",\n",
    "    }\n",
    "\n",
    "    metrics_by_slice[slice_name] = metrics\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"   MIRAGE-AWARE GEMMA 2B: EVALUATION RESULTS [{slice_name}]\")\n",
    "    print(\"=\" * 70)\n",
    "    for k, v in metrics.items():\n",
    "        if v == \"\":\n",
    "            print(k)\n",
    "        else:\n",
    "            print(f\"  {k:50s} {v}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "headline_slice = \"balanced_400\" if \"balanced_400\" in rows_by_slice else next(iter(rows_by_slice))\n",
    "headline_rows = rows_by_slice[headline_slice]\n",
    "headline_degraded = [r for r in headline_rows if r[\"oracle_degraded\"]]\n",
    "headline_strong = [r for r in headline_rows if not r[\"oracle_degraded\"]]\n",
    "degraded_and_wrong_ft = [r for r in headline_degraded if not r[\"ft_pivot_correct\"]]\n",
    "\n",
    "metrics = metrics_by_slice[headline_slice]\n",
    "base_sr = safe_rate(headline_degraded, \"base_silent_mirage\")\n",
    "ft_sr = safe_rate(headline_degraded, \"ft_silent_mirage\")\n",
    "ft_flag = safe_rate(headline_degraded, \"ft_flagged_degraded\")\n",
    "ft_fa = safe_rate(headline_strong, \"ft_flagged_degraded\")\n",
    "ft_flag_given_wrong = safe_rate(degraded_and_wrong_ft, \"ft_flagged_degraded\") if degraded_and_wrong_ft else float(\"nan\")\n",
    "\n",
    "print(f\"\\nHeadline slice for verdicts: {headline_slice}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Stratified metrics by difficulty and category (for each eval slice)\n",
    "for slice_name, rows in rows_by_slice.items():\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"   STRATIFIED BY DIFFICULTY [{slice_name}]\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    for diff in [\"easy\", \"medium\", \"hard\", \"extreme\"]:\n",
    "        subset = [r for r in rows if r[\"difficulty\"] == diff]\n",
    "        if not subset:\n",
    "            continue\n",
    "        deg_sub = [r for r in subset if r[\"oracle_degraded\"]]\n",
    "        str_sub = [r for r in subset if not r[\"oracle_degraded\"]]\n",
    "\n",
    "        base_acc = safe_rate(subset, \"base_pivot_correct\")\n",
    "        ft_acc = safe_rate(subset, \"ft_pivot_correct\")\n",
    "\n",
    "        ft_flag_deg = safe_rate(deg_sub, \"ft_flagged_degraded\") if deg_sub else 0\n",
    "        ft_silent = safe_rate(deg_sub, \"ft_silent_mirage\") if deg_sub else 0\n",
    "\n",
    "        deg_wrong = [r for r in deg_sub if not r[\"ft_pivot_correct\"]]\n",
    "        fgw = safe_rate(deg_wrong, \"ft_flagged_degraded\") if deg_wrong else float(\"nan\")\n",
    "        fgw_str = f\"{fgw:.1%}\" if deg_wrong else \"N/A\"\n",
    "\n",
    "        print(f\"\\n  {diff.upper()} (n={len(subset)}, {len(deg_sub)} degraded, {len(str_sub)} strong)\")\n",
    "        print(f\"    Pivot acc:        base={base_acc:.1%}  FT={ft_acc:.1%}\")\n",
    "        print(f\"    FT flag (deg):    {ft_flag_deg:.1%}\")\n",
    "        print(f\"    FT silent mirage: {ft_silent:.1%}\")\n",
    "        print(f\"    FT flag|wrong:    {fgw_str} ({len(deg_wrong)} wrong cases)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"   STRATIFIED BY CATEGORY [{slice_name}]\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    for cat in [\"investment\", \"incident\", \"narrative\"]:\n",
    "        subset = [r for r in rows if r[\"category\"] == cat]\n",
    "        if not subset:\n",
    "            continue\n",
    "        deg_sub = [r for r in subset if r[\"oracle_degraded\"]]\n",
    "        str_sub = [r for r in subset if not r[\"oracle_degraded\"]]\n",
    "\n",
    "        base_acc = safe_rate(subset, \"base_pivot_correct\")\n",
    "        ft_acc = safe_rate(subset, \"ft_pivot_correct\")\n",
    "        ft_flag_deg = safe_rate(deg_sub, \"ft_flagged_degraded\") if deg_sub else 0\n",
    "        ft_silent = safe_rate(deg_sub, \"ft_silent_mirage\") if deg_sub else 0\n",
    "\n",
    "        deg_wrong = [r for r in deg_sub if not r[\"ft_pivot_correct\"]]\n",
    "        fgw = safe_rate(deg_wrong, \"ft_flagged_degraded\") if deg_wrong else float(\"nan\")\n",
    "        fgw_str = f\"{fgw:.1%}\" if deg_wrong else \"N/A\"\n",
    "\n",
    "        print(f\"\\n  {cat.upper()} (n={len(subset)}, {len(deg_sub)} degraded, {len(str_sub)} strong)\")\n",
    "        print(f\"    Pivot acc:        base={base_acc:.1%}  FT={ft_acc:.1%}\")\n",
    "        print(f\"    FT flag (deg):    {ft_flag_deg:.1%}\")\n",
    "        print(f\"    FT silent mirage: {ft_silent:.1%}\")\n",
    "        print(f\"    FT flag|wrong:    {fgw_str} ({len(deg_wrong)} wrong cases)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Print 5 side-by-side examples from headline slice\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"SAMPLE OUTPUTS (5 examples) [{headline_slice}]\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rows = rows_by_slice[headline_slice]\n",
    "base_results = base_results_by_slice[headline_slice]\n",
    "ft_results = ft_results_by_slice[headline_slice]\n",
    "\n",
    "deg_idx = [i for i, r in enumerate(rows) if r[\"oracle_degraded\"]][:3]\n",
    "str_idx = [i for i, r in enumerate(rows) if not r[\"oracle_degraded\"]][:2]\n",
    "sample_indices = deg_idx + str_idx\n",
    "\n",
    "for idx in sample_indices:\n",
    "    r = rows[idx]\n",
    "    status = \"DEGRADED\" if r[\"oracle_degraded\"] else \"STRONG\"\n",
    "    print(f\"\\n--- Example {idx} ({status}, difficulty={r['difficulty']}, category={r['category']}) ---\")\n",
    "    print(f\"Oracle pivot: {r['oracle_pivot']}\")\n",
    "\n",
    "    print(\"\\nBASE response (first 400 chars):\")\n",
    "    print(base_results[idx][\"response\"][:400])\n",
    "\n",
    "    print(\"\\nFINE-TUNED response (first 400 chars):\")\n",
    "    print(ft_results[idx][\"response\"][:400])\n",
    "\n",
    "    print(f\"\\nBase: pivot={r['base_pivot']}, strict_flagged={r['base_flagged_degraded']}, loose_flagged={r['base_flagged_degraded_loose']}\")\n",
    "    print(f\"FT:   pivot={r['ft_pivot']}, strict_flagged={r['ft_flagged_degraded']}, loose_flagged={r['ft_flagged_degraded_loose']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Download Results\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Save summary\n",
    "summary_path = \"/content/mirage_aware_gemma2b_eval_summary.json\"\n",
    "summary_payload = {\n",
    "    \"headline_slice\": headline_slice,\n",
    "    \"metrics_by_slice\": metrics_by_slice,\n",
    "}\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump(summary_payload, f, indent=2)\n",
    "\n",
    "# Save per-example rows as JSON for easy reuse.\n",
    "rows_path = \"/content/mirage_aware_gemma2b_eval_rows.json\"\n",
    "with open(rows_path, \"w\") as f:\n",
    "    json.dump(all_rows, f, indent=2)\n",
    "\n",
    "# Package adapter + results for download\n",
    "!cd /content && tar czf mirage_aware_gemma2b_package.tar.gz \\\n",
    "    mirage_aware_gemma2b_adapter/ \\\n",
    "    mirage_aware_gemma2b_eval_results.csv \\\n",
    "    mirage_aware_gemma2b_eval_summary.json \\\n",
    "    mirage_aware_gemma2b_eval_rows.json \\\n",
    "    base_raw_responses.json \\\n",
    "    ft_raw_responses.json \\\n",
    "    base_raw_responses_natural_400.json \\\n",
    "    base_raw_responses_balanced_400.json \\\n",
    "    ft_raw_responses_natural_400.json \\\n",
    "    ft_raw_responses_balanced_400.json \\\n",
    "    base_results_backup.json \\\n",
    "    ft_results_backup.json \\\n",
    "    training_loss.png\n",
    "\n",
    "print(\"\\nPackage created. Downloading...\")\n",
    "print(\"Contents:\")\n",
    "print(\"  - mirage_aware_gemma2b_adapter/ (LoRA weights)\")\n",
    "print(\"  - mirage_aware_gemma2b_eval_results.csv (per-example results)\")\n",
    "print(\"  - mirage_aware_gemma2b_eval_summary.json (summary metrics by slice)\")\n",
    "print(\"  - mirage_aware_gemma2b_eval_rows.json (full rows)\")\n",
    "print(\"  - base_raw_responses*.json / ft_raw_responses*.json (raw outputs)\")\n",
    "print(\"  - base_results_backup.json / ft_results_backup.json (parsed outputs)\")\n",
    "print(\"  - training_loss.png (loss curve)\")\n",
    "\n",
    "files.download(\"/content/mirage_aware_gemma2b_package.tar.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "print(\"Done. Check the summary tables above for results.\")\n",
    "print(f\"\\nHeadline slice: {headline_slice}\")\n",
    "print(\"Key question: Did the fine-tuned model learn to flag DEGRADED when it is wrong?\")\n",
    "print(f\"  Base silent mirage rate: {base_sr:.1%}\")\n",
    "print(f\"  FT silent mirage rate: {ft_sr:.1%}\")\n",
    "print(f\"  FT degradation detection (strict): {ft_flag:.1%}\")\n",
    "print(f\"  FT false alarm rate (strict): {ft_fa:.1%}\")\n",
    "if degraded_and_wrong_ft:\n",
    "    print(f\"  FT flag_given_wrong (strict): {ft_flag_given_wrong:.1%}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "a792942fd8384c89bb44109f4e5e5031": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_86f2d11e8e7b4487803cdc76a527bff3",
       "IPY_MODEL_3fb0d294e0a14f2191ef293057a2d9b8",
       "IPY_MODEL_e3de2b7d304245b290bf4b2132ec5cab"
      ],
      "layout": "IPY_MODEL_3cea48dbcbe44cd78e126895ba8df9e2"
     }
    },
    "86f2d11e8e7b4487803cdc76a527bff3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d21396b84814aa19816a3cce7fb302e",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_a089bff5819742148cc53153c9b11c61",
      "value": "Loading\u2007checkpoint\u2007shards:\u2007100%"
     }
    },
    "3fb0d294e0a14f2191ef293057a2d9b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca5d1244e7ef4117a740a211adf20bbe",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fa4aa55f0444516b2ef9511356b2673",
      "value": 4
     }
    },
    "e3de2b7d304245b290bf4b2132ec5cab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8030ca9f12da42b7ab3e24c331343618",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_4b342bc0365f4e97952258904015d2ff",
      "value": "\u20074/4\u2007[00:06&lt;00:00,\u2007\u20071.55s/it]"
     }
    },
    "3cea48dbcbe44cd78e126895ba8df9e2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d21396b84814aa19816a3cce7fb302e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a089bff5819742148cc53153c9b11c61": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca5d1244e7ef4117a740a211adf20bbe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fa4aa55f0444516b2ef9511356b2673": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8030ca9f12da42b7ab3e24c331343618": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b342bc0365f4e97952258904015d2ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0dd6e53d38641bbbea1234ba149e847": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bb9dd55a41e4173a728294eaa48fcfc",
       "IPY_MODEL_18aeede7cf6840f38eeb0862184c6c69",
       "IPY_MODEL_710190d649f2400d80800e2361fe2469"
      ],
      "layout": "IPY_MODEL_241a8ddef6294c268d2ba11cac584cad"
     }
    },
    "8bb9dd55a41e4173a728294eaa48fcfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9a4a0a16ae642c888c8c0725bb08d41",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_8af3a9692fc841acb27080a12aef015e",
      "value": "Map:\u2007100%"
     }
    },
    "18aeede7cf6840f38eeb0862184c6c69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fec9578b1e874288949ddc48beedfaed",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b17c452f52424f0faf3fef18520c4cc1",
      "value": 2000
     }
    },
    "710190d649f2400d80800e2361fe2469": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2634367ef3fd41cc8c1b2e3e1d57da33",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_892f9e1198e947b69be361d2473d40be",
      "value": "\u20072000/2000\u2007[00:03&lt;00:00,\u2007596.87\u2007examples/s]"
     }
    },
    "241a8ddef6294c268d2ba11cac584cad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9a4a0a16ae642c888c8c0725bb08d41": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8af3a9692fc841acb27080a12aef015e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fec9578b1e874288949ddc48beedfaed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b17c452f52424f0faf3fef18520c4cc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2634367ef3fd41cc8c1b2e3e1d57da33": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "892f9e1198e947b69be361d2473d40be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce7f49a0b94945059f86c1adee217afd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a22b70891b22453e9b63fa10e4cf11e1",
       "IPY_MODEL_f3711d52dc184488a33119dca6ff8639",
       "IPY_MODEL_d14db2339c2e475b84c49c0cf6abe43e"
      ],
      "layout": "IPY_MODEL_a8327a6b3ca34470a536795592fd1c3c"
     }
    },
    "a22b70891b22453e9b63fa10e4cf11e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98ed268efc9c44fdb3629cea36e7de18",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_310d06e9e2364361a1491b116b72a6d7",
      "value": "Map:\u2007100%"
     }
    },
    "f3711d52dc184488a33119dca6ff8639": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_183ae199b5074b90b901c250c28583f6",
      "max": 400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3d9807f9846458da613cd55b615e326",
      "value": 400
     }
    },
    "d14db2339c2e475b84c49c0cf6abe43e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95522b115c044309b5d0a90daf23d0f7",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_97c3927447424d4fa96225ce9cb5bcfa",
      "value": "\u2007400/400\u2007[00:00&lt;00:00,\u2007621.09\u2007examples/s]"
     }
    },
    "a8327a6b3ca34470a536795592fd1c3c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98ed268efc9c44fdb3629cea36e7de18": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "310d06e9e2364361a1491b116b72a6d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "183ae199b5074b90b901c250c28583f6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3d9807f9846458da613cd55b615e326": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "95522b115c044309b5d0a90daf23d0f7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97c3927447424d4fa96225ce9cb5bcfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d8f81eee1e064fd8ab117832893b4e86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff6d7f68aaad4932a87077f9bd7cc478",
       "IPY_MODEL_5dd6b2b2d8054a01bff19495769a5260",
       "IPY_MODEL_edd6d5f097514515a777bc8684132018"
      ],
      "layout": "IPY_MODEL_876fff3e57d44da28f5e7faca548d007"
     }
    },
    "ff6d7f68aaad4932a87077f9bd7cc478": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40379340ad88489fa2ed63e8570781bc",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_ca99a96c7a324754a8a0f00f80b1c953",
      "value": "Loading\u2007checkpoint\u2007shards:\u2007100%"
     }
    },
    "5dd6b2b2d8054a01bff19495769a5260": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a88f91554f3049dc82e778f86c6f706a",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f1115bcf344490c8c860df211db9a62",
      "value": 4
     }
    },
    "edd6d5f097514515a777bc8684132018": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9eba85acdb0a4c5fbf6fc76ba94b45fd",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_5fa218551f09416aa31d0b86652e4297",
      "value": "\u20074/4\u2007[00:06&lt;00:00,\u2007\u20071.63s/it]"
     }
    },
    "876fff3e57d44da28f5e7faca548d007": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40379340ad88489fa2ed63e8570781bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca99a96c7a324754a8a0f00f80b1c953": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a88f91554f3049dc82e778f86c6f706a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f1115bcf344490c8c860df211db9a62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9eba85acdb0a4c5fbf6fc76ba94b45fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fa218551f09416aa31d0b86652e4297": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f1bccb7a09a48ea839127d270288fdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d69b3af2275148f5a417323db8566e03",
       "IPY_MODEL_51fd0f65eaba42ae82478d525f1061d0",
       "IPY_MODEL_3e574eb7a14546ce825f6cb38680ee23"
      ],
      "layout": "IPY_MODEL_3bf2e4865c0544078ea78ea83faa747c"
     }
    },
    "d69b3af2275148f5a417323db8566e03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9660a7c667d54dfc9adc94c0f2b209b1",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_db1df73f1179425db39b398a252183bc",
      "value": "Loading\u2007checkpoint\u2007shards:\u2007100%"
     }
    },
    "51fd0f65eaba42ae82478d525f1061d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77f789af8b864e7aba4c0e85e7690b38",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b4756ff48fa2434c8e292dd04be936fd",
      "value": 4
     }
    },
    "3e574eb7a14546ce825f6cb38680ee23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a03d5e81e94b4c859b934c449d43e653",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_1c2bca2ffa1c46cd9c9c1ba74d6e1716",
      "value": "\u20074/4\u2007[00:05&lt;00:00,\u2007\u20071.48s/it]"
     }
    },
    "3bf2e4865c0544078ea78ea83faa747c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9660a7c667d54dfc9adc94c0f2b209b1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db1df73f1179425db39b398a252183bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77f789af8b864e7aba4c0e85e7690b38": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4756ff48fa2434c8e292dd04be936fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a03d5e81e94b4c859b934c449d43e653": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c2bca2ffa1c46cd9c9c1ba74d6e1716": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}