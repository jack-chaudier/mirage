{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mirage-Aware Fine-Tuning: Qwen 2.5 7B LoRA (A100)\n",
    "\n",
    "This notebook fine-tunes **Qwen/Qwen2.5-7B-Instruct** with QLoRA to detect and flag\n",
    "when context compression degrades evidence, instead of silently switching hypotheses.\n",
    "\n",
    "**Requirements:** Colab with A100 GPU.\n",
    "\n",
    "**Runtime:** ~45-60 minutes for training + full validation eval.\n",
    "\n",
    "**Inputs:** `train.jsonl` and `valid.jsonl` (upload when prompted).\n",
    "\n",
    "**Outputs:** LoRA adapter + eval CSV + summary JSON + raw response backups.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -q transformers==4.46.3 peft==0.13.2 trl==0.12.2 accelerate==1.1.1 bitsandbytes>=0.46.1 datasets matplotlib\n",
    "print(\"Dependencies installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Verify GPU\n",
    "import torch\n",
    "assert torch.cuda.is_available(), \"No GPU detected! Go to Runtime > Change runtime type > GPU\"\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "print(f\"GPU: {gpu_name} ({gpu_mem:.1f} GB)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Training Data\n",
    "\n",
    "Upload your `train.jsonl` and `valid.jsonl` files when the file picker appears.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from google.colab import files\n",
    "\n",
    "DATA_DIR = \"/content/training_data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(DATA_DIR, \"train.jsonl\")\n",
    "valid_path = os.path.join(DATA_DIR, \"valid.jsonl\")\n",
    "\n",
    "if not os.path.exists(train_path) or not os.path.exists(valid_path):\n",
    "    print(\"Upload train.jsonl and valid.jsonl:\")\n",
    "    uploaded = files.upload()\n",
    "    for fname, content in uploaded.items():\n",
    "        dest = os.path.join(DATA_DIR, fname)\n",
    "        with open(dest, \"wb\") as f:\n",
    "            f.write(content)\n",
    "        print(f\"  Saved {fname} -> {dest}\")\n",
    "else:\n",
    "    print(f\"Data already present at {DATA_DIR}\")\n",
    "\n",
    "\n",
    "def count_and_check(path):\n",
    "    count = 0\n",
    "    strong = 0\n",
    "    degraded = 0\n",
    "    for line in open(path):\n",
    "        obj = json.loads(line)\n",
    "        assert \"messages\" in obj, f\"Missing 'messages' key in {path}\"\n",
    "        assert len(obj[\"messages\"]) >= 2, f\"Need at least 2 messages in {path}\"\n",
    "        content = obj[\"messages\"][1][\"content\"]\n",
    "        if \"STRONG\" in content:\n",
    "            strong += 1\n",
    "        if \"DEGRADED\" in content:\n",
    "            degraded += 1\n",
    "        count += 1\n",
    "    return count, strong, degraded\n",
    "\n",
    "\n",
    "for p, name in [(train_path, \"Train\"), (valid_path, \"Valid\")]:\n",
    "    n, s, d = count_and_check(p)\n",
    "    pct = d / n * 100 if n > 0 else 0\n",
    "    print(f\"{name}: {n} examples ({s} STRONG, {d} DEGRADED, {pct:.0f}% degraded)\")\n",
    "\n",
    "print(\"\\nData verified.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "print(f\"Loading {MODEL_ID} in 4-bit...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "print(f\"Model loaded. Memory: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure LoRA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "trainable, total = model.get_nb_trainable_parameters()\n",
    "print(f\"Trainable: {trainable:,} / {total:,} ({100*trainable/total:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files={\n",
    "    \"train\": train_path,\n",
    "    \"validation\": valid_path,\n",
    "})\n",
    "\n",
    "print(f\"Train: {len(dataset['train'])} examples\")\n",
    "print(f\"Valid: {len(dataset['validation'])} examples\")\n",
    "\n",
    "# Keep only messages for SFT training.\n",
    "train_cols = [c for c in dataset[\"train\"].column_names if c != \"messages\"]\n",
    "valid_cols = [c for c in dataset[\"validation\"].column_names if c != \"messages\"]\n",
    "\n",
    "train_data = dataset[\"train\"].remove_columns(train_cols)\n",
    "valid_data = dataset[\"validation\"].remove_columns(valid_cols)\n",
    "print(f\"Stripped extra columns: {train_cols}\")\n",
    "\n",
    "\n",
    "def format_chat(example):\n",
    "    text = tokenizer.apply_chat_template(example[\"messages\"], tokenize=False)\n",
    "    return {\"text\": text}\n",
    "\n",
    "\n",
    "train_data = train_data.map(format_chat, remove_columns=[\"messages\"])\n",
    "valid_data = valid_data.map(format_chat, remove_columns=[\"messages\"])\n",
    "\n",
    "print(f\"Train columns: {train_data.column_names}\")\n",
    "print(f\"Valid columns: {valid_data.column_names}\")\n",
    "print(\"\\nSample formatted text (first 500 chars):\")\n",
    "print(train_data[0][\"text\"][:500] + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sequence length diagnostic\n",
    "MAX_SEQ = 2560  # must match training config\n",
    "\n",
    "lengths = []\n",
    "assistant_visible = {\"full\": 0, \"partial\": 0, \"none\": 0}\n",
    "\n",
    "response_marker = \"<|im_start|>assistant\\n\"\n",
    "for ex in train_data:\n",
    "    tokens = tokenizer(ex[\"text\"], truncation=False)[\"input_ids\"]\n",
    "    total_len = len(tokens)\n",
    "    lengths.append(total_len)\n",
    "\n",
    "    text = ex[\"text\"]\n",
    "    asst_start_char = text.find(response_marker)\n",
    "    if asst_start_char >= 0:\n",
    "        prefix = text[: asst_start_char + len(response_marker)]\n",
    "        prefix_tokens = len(tokenizer(prefix, truncation=False)[\"input_ids\"])\n",
    "\n",
    "        if prefix_tokens >= MAX_SEQ:\n",
    "            assistant_visible[\"none\"] += 1\n",
    "        elif total_len <= MAX_SEQ:\n",
    "            assistant_visible[\"full\"] += 1\n",
    "        else:\n",
    "            assistant_visible[\"partial\"] += 1\n",
    "\n",
    "n = len(lengths)\n",
    "print(f\"Sequence length stats (n={n}):\")\n",
    "print(f\"  Mean: {sum(lengths)/n:.0f}, Max: {max(lengths)}, Min: {min(lengths)}\")\n",
    "over = sum(1 for l in lengths if l > MAX_SEQ)\n",
    "print(f\"  Over {MAX_SEQ}: {over} ({over/n:.1%})\")\n",
    "\n",
    "print(f\"\\nAssistant token visibility at max_seq_length={MAX_SEQ}:\")\n",
    "for k, v in assistant_visible.items():\n",
    "    print(f\"  {k}: {v} ({v/n:.1%})\")\n",
    "\n",
    "if assistant_visible[\"none\"] > n * 0.1:\n",
    "    print(f\"\\nWARNING: {assistant_visible['none']/n:.0%} of examples have NO assistant tokens at max_seq_length={MAX_SEQ}!\")\n",
    "    print(\"Consider increasing max_seq_length or shortening context in data generation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Completion-only loss masking (train only on assistant response)\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "\n",
    "response_template = \"<|im_start|>assistant\\n\"\n",
    "completion_collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template=response_template,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Verify masking on a small sample batch.\n",
    "sample_features = [\n",
    "    tokenizer(train_data[i][\"text\"], truncation=True, max_length=2560)\n",
    "    for i in range(min(2, len(train_data)))\n",
    "]\n",
    "sample_batch = completion_collator(sample_features)\n",
    "labels = sample_batch[\"labels\"]\n",
    "masked = int((labels == -100).sum().item())\n",
    "active = int((labels != -100).sum().item())\n",
    "print(f\"Collator check: masked={masked}, active={active}\")\n",
    "assert masked > 0, \"Expected masked prompt tokens (-100).\"\n",
    "assert active > 0, \"Expected some assistant tokens to contribute to loss.\"\n",
    "print(\"Completion-only collator ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "OUTPUT_DIR = \"/content/mirage_aware_adapter\"\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    max_seq_length=2560,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=250,\n",
    "    per_device_eval_batch_size=1,\n",
    "    seed=42,\n",
    "    report_to=\"none\",\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    packing=False,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=valid_data,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=completion_collator,\n",
    ")\n",
    "\n",
    "print(f\"Starting training ({len(dataset['train'])} examples, {training_args.num_train_epochs} epochs)...\")\n",
    "print(\n",
    "    \"Estimated steps:\",\n",
    "    len(dataset[\"train\"]) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps) * training_args.num_train_epochs,\n",
    ")\n",
    "print()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(f\"\\nAdapter saved to {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = trainer.state.log_history\n",
    "train_steps = [l[\"step\"] for l in logs if \"loss\" in l and \"eval_loss\" not in l]\n",
    "train_loss = [l[\"loss\"] for l in logs if \"loss\" in l and \"eval_loss\" not in l]\n",
    "eval_steps = [l[\"step\"] for l in logs if \"eval_loss\" in l]\n",
    "eval_loss = [l[\"eval_loss\"] for l in logs if \"eval_loss\" in l]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_steps, train_loss, label=\"Train\", alpha=0.7)\n",
    "if eval_steps:\n",
    "    plt.plot(eval_steps, eval_loss, \"ro-\", label=\"Eval\", markersize=6)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Mirage-Aware Training Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/content/training_loss.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "if train_loss:\n",
    "    print(f\"Final train loss: {train_loss[-1]:.4f}\")\n",
    "if eval_loss:\n",
    "    print(f\"Final eval loss: {eval_loss[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate: Base vs Fine-Tuned"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Free training model memory before eval models are loaded.\n",
    "for var_name in [\"trainer\", \"model\"]:\n",
    "    if var_name in globals():\n",
    "        del globals()[var_name]\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Training resources freed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "\n",
    "def load_base_model():\n",
    "    # Load the base model in 4-bit.\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_finetuned_model(adapter_path):\n",
    "    # Load base + LoRA adapter.\n",
    "    base = load_base_model()\n",
    "    return PeftModel.from_pretrained(base, adapter_path)\n",
    "\n",
    "\n",
    "def generate_response(model, tokenizer, prompt, max_new_tokens=512):\n",
    "    # Generate a response from a prompt string.\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    input_text = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    new_tokens = outputs[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    return tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def extract_pivot(text):\n",
    "    # Extract pivot ID. Supports 1-4 digit actor IDs.\n",
    "    match = re.search(r\"PIVOT_ID\\s*=\\s*([A-Z]\\d{1,4}-E\\d{3})\", text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    # Fallback: find any pivot-shaped ID in text\n",
    "    match = re.search(r\"([A-Z]\\d{1,4}-E\\d{3})\", text)\n",
    "    return match.group(1) if match else \"UNKNOWN\"\n",
    "\n",
    "\n",
    "def check_degraded_flag(text):\n",
    "    # Check if model flagged evidence as degraded.\n",
    "    if re.search(r\"Evidence assessment:\\s*DEGRADED\", text, re.IGNORECASE):\n",
    "        return True\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    return any(\n",
    "        kw in text_lower\n",
    "        for kw in [\n",
    "            \"degraded\",\n",
    "            \"incomplete\",\n",
    "            \"missing prerequisite\",\n",
    "            \"compressed evidence\",\n",
    "            \"not found in context\",\n",
    "            \"confidence: low\",\n",
    "            \"evidence_status=degraded\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def check_format_adherence(text):\n",
    "    # Check if response follows the structured output protocol.\n",
    "    has_pivot = bool(re.search(r\"PIVOT_ID\\s*=\", text))\n",
    "    has_evidence = bool(\n",
    "        re.search(r\"Evidence assessment:\\s*(STRONG|DEGRADED)\", text, re.IGNORECASE)\n",
    "    )\n",
    "    return has_pivot and has_evidence\n",
    "\n",
    "\n",
    "print(\"Helper functions defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load validation data with oracle metadata\n",
    "valid_examples = []\n",
    "with open(valid_path) as f:\n",
    "    for line in f:\n",
    "        valid_examples.append(json.loads(line))\n",
    "\n",
    "# Evaluate on ALL validation examples.\n",
    "EVAL_N = 400\n",
    "eval_subset = valid_examples[:EVAL_N]\n",
    "\n",
    "print(f\"Will evaluate on {EVAL_N} examples.\")\n",
    "\n",
    "sample = eval_subset[0]\n",
    "oracle_fields = [k for k in sample.keys() if k != \"messages\"]\n",
    "print(f\"Oracle metadata fields: {oracle_fields}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optional: upload precomputed base results (from mirage_aware_base_eval.ipynb)\n",
    "import os\n",
    "import json\n",
    "from google.colab import files\n",
    "\n",
    "\n",
    "def _normalize_base_results(records):\n",
    "    normalized = []\n",
    "    for r in records:\n",
    "        response = r.get(\"response\", \"\")\n",
    "        normalized.append(\n",
    "            {\n",
    "                \"response\": response,\n",
    "                \"pivot\": r.get(\"pivot\", extract_pivot(response)),\n",
    "                \"flagged_degraded\": r.get(\"flagged_degraded\", check_degraded_flag(response)),\n",
    "                \"flagged_degraded_strict\": r.get(\n",
    "                    \"flagged_degraded_strict\",\n",
    "                    bool(re.search(r\"Evidence assessment:\\s*DEGRADED\", response, re.IGNORECASE)),\n",
    "                ),\n",
    "                \"format_ok\": r.get(\"format_ok\", check_format_adherence(response)),\n",
    "            }\n",
    "        )\n",
    "    return normalized\n",
    "\n",
    "\n",
    "print(\"Upload base_results_backup.json from your base-eval run (H100) to skip base eval here.\")\n",
    "uploaded = files.upload()\n",
    "for fname, content in uploaded.items():\n",
    "    dest = f\"/content/{fname}\"\n",
    "    with open(dest, \"wb\") as f:\n",
    "        f.write(content)\n",
    "    print(f\"  Saved {fname} -> {dest}\")\n",
    "\n",
    "precomp_path = \"/content/base_results_backup.json\"\n",
    "if os.path.exists(precomp_path):\n",
    "    with open(precomp_path) as f:\n",
    "        base_results = _normalize_base_results(json.load(f))\n",
    "\n",
    "    if len(base_results) != EVAL_N:\n",
    "        raise ValueError(\n",
    "            f\"Loaded base_results has {len(base_results)} rows but EVAL_N={EVAL_N}. \"\n",
    "            \"Use matching base-eval settings (seed=42, EVAL_N=400) or update EVAL_N.\"\n",
    "        )\n",
    "\n",
    "    # Ensure package artifacts exist even when we skip base inference.\n",
    "    with open(\"/content/base_raw_responses.json\", \"w\") as f:\n",
    "        json.dump(\n",
    "            [{\"idx\": i, \"response\": r[\"response\"]} for i, r in enumerate(base_results)],\n",
    "            f,\n",
    "        )\n",
    "    with open(\"/content/base_results_backup.json\", \"w\") as f:\n",
    "        json.dump(base_results, f)\n",
    "\n",
    "    print(f\"Loaded precomputed base results: {len(base_results)} rows\")\n",
    "    print(\"Next cell will auto-skip base model inference.\")\n",
    "else:\n",
    "    print(\"No base_results_backup.json uploaded. Next cell will run base model eval.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run BASE model eval\n",
    "if \"base_results\" in globals() and isinstance(base_results, list):\n",
    "    if len(base_results) != EVAL_N:\n",
    "        raise ValueError(\n",
    "            f\"Loaded precomputed base_results has {len(base_results)} rows but EVAL_N={EVAL_N}. \"\n",
    "            \"Use a matching eval slice or update EVAL_N.\"\n",
    "        )\n",
    "    print(f\"Using precomputed base results ({len(base_results)} rows). Skipping base model inference.\")\n",
    "else:\n",
    "    print(\"Loading BASE model...\")\n",
    "    base_model = load_base_model()\n",
    "    base_tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "    if base_tokenizer.pad_token is None:\n",
    "        base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "\n",
    "    base_results = []\n",
    "    print(f\"Generating {EVAL_N} base model responses...\")\n",
    "    for i, ex in enumerate(eval_subset):\n",
    "        prompt = ex[\"messages\"][0][\"content\"]\n",
    "        response = generate_response(base_model, base_tokenizer, prompt)\n",
    "        base_results.append(\n",
    "            {\n",
    "                \"response\": response,\n",
    "                \"pivot\": extract_pivot(response),\n",
    "                \"flagged_degraded\": check_degraded_flag(response),\n",
    "                \"format_ok\": check_format_adherence(response),\n",
    "            }\n",
    "        )\n",
    "        if (i + 1) % 20 == 0 or (i + 1) == EVAL_N:\n",
    "            print(f\"  [{i+1}/{EVAL_N}] done\")\n",
    "\n",
    "    # Save raw responses for re-parsing without rerunning inference.\n",
    "    model_type = \"base\"\n",
    "    results = base_results\n",
    "    with open(f\"/content/{model_type}_raw_responses.json\", \"w\") as f:\n",
    "        json.dump([{\"idx\": i, \"response\": r[\"response\"]} for i, r in enumerate(results)], f)\n",
    "    print(\"Raw responses saved.\")\n",
    "\n",
    "    with open(\"/content/base_results_backup.json\", \"w\") as f:\n",
    "        json.dump(base_results, f)\n",
    "    print(f\"Saved {len(base_results)} base results\")\n",
    "\n",
    "    # Free base model\n",
    "    del base_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Base model eval complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run FINE-TUNED model eval\n",
    "OUTPUT_DIR = \"/content/mirage_aware_adapter\"\n",
    "print(\"Loading FINE-TUNED model...\")\n",
    "ft_model = load_finetuned_model(OUTPUT_DIR)\n",
    "ft_tokenizer = AutoTokenizer.from_pretrained(OUTPUT_DIR)\n",
    "if ft_tokenizer.pad_token is None:\n",
    "    ft_tokenizer.pad_token = ft_tokenizer.eos_token\n",
    "\n",
    "ft_results = []\n",
    "print(f\"Generating {EVAL_N} fine-tuned model responses...\")\n",
    "for i, ex in enumerate(eval_subset):\n",
    "    prompt = ex[\"messages\"][0][\"content\"]\n",
    "    response = generate_response(ft_model, ft_tokenizer, prompt)\n",
    "    ft_results.append(\n",
    "        {\n",
    "            \"response\": response,\n",
    "            \"pivot\": extract_pivot(response),\n",
    "            \"flagged_degraded\": check_degraded_flag(response),\n",
    "            \"format_ok\": check_format_adherence(response),\n",
    "        }\n",
    "    )\n",
    "    if (i + 1) % 20 == 0 or (i + 1) == EVAL_N:\n",
    "        print(f\"  [{i+1}/{EVAL_N}] done\")\n",
    "\n",
    "# Save raw responses for re-parsing without rerunning inference.\n",
    "model_type = \"ft\"\n",
    "results = ft_results\n",
    "with open(f\"/content/{model_type}_raw_responses.json\", \"w\") as f:\n",
    "    json.dump([{\"idx\": i, \"response\": r[\"response\"]} for i, r in enumerate(results)], f)\n",
    "print(\"Raw responses saved.\")\n",
    "\n",
    "with open(\"/content/ft_results_backup.json\", \"w\") as f:\n",
    "    json.dump(ft_results, f)\n",
    "print(f\"Saved {len(ft_results)} fine-tuned results\")\n",
    "\n",
    "del ft_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Fine-tuned model eval complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compute Metrics & Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Build per-example results\n",
    "rows = []\n",
    "for i, ex in enumerate(eval_subset):\n",
    "    target_content = ex[\"messages\"][1][\"content\"]\n",
    "    target_pivot = extract_pivot(target_content)\n",
    "    is_degraded = \"DEGRADED\" in target_content\n",
    "\n",
    "    oracle_pivot = ex.get(\"oracle_pivot\", target_pivot)\n",
    "    evidence_degraded = bool(ex.get(\"evidence_degraded\", is_degraded))\n",
    "    prereq_ratio = ex.get(\"prereq_ratio\", None)\n",
    "    difficulty = ex.get(\"difficulty\", \"unknown\")\n",
    "    category = ex.get(\"category\", \"unknown\")\n",
    "    compression_level = ex.get(\"compression_level\", None)\n",
    "    is_full_context = ex.get(\"is_full_context\", None)\n",
    "\n",
    "    br = base_results[i]\n",
    "    fr = ft_results[i]\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"example_idx\": i,\n",
    "            \"category\": category,\n",
    "            \"difficulty\": difficulty,\n",
    "            \"compression_level\": compression_level,\n",
    "            \"is_full_context\": is_full_context,\n",
    "            \"oracle_degraded\": evidence_degraded,\n",
    "            \"prereq_ratio\": prereq_ratio,\n",
    "            \"oracle_pivot\": oracle_pivot,\n",
    "            \"target_pivot\": target_pivot,\n",
    "            # Base model\n",
    "            \"base_pivot\": br[\"pivot\"],\n",
    "            \"base_pivot_correct\": br[\"pivot\"] == oracle_pivot,\n",
    "            \"base_flagged_degraded\": br[\"flagged_degraded\"],\n",
    "            \"base_format_ok\": br[\"format_ok\"],\n",
    "            \"base_silent_mirage\": evidence_degraded and (br[\"pivot\"] != oracle_pivot) and not br[\"flagged_degraded\"],\n",
    "            # Fine-tuned model\n",
    "            \"ft_pivot\": fr[\"pivot\"],\n",
    "            \"ft_pivot_correct\": fr[\"pivot\"] == oracle_pivot,\n",
    "            \"ft_flagged_degraded\": fr[\"flagged_degraded\"],\n",
    "            \"ft_format_ok\": fr[\"format_ok\"],\n",
    "            \"ft_silent_mirage\": evidence_degraded and (fr[\"pivot\"] != oracle_pivot) and not fr[\"flagged_degraded\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "results_csv = \"/content/mirage_aware_eval_results.csv\"\n",
    "with open(results_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=rows[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Detailed results saved to {results_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute summary metrics\n",
    "n = len(rows)\n",
    "degraded_rows = [r for r in rows if r[\"oracle_degraded\"]]\n",
    "strong_rows = [r for r in rows if not r[\"oracle_degraded\"]]\n",
    "n_deg = len(degraded_rows)\n",
    "n_str = len(strong_rows)\n",
    "\n",
    "\n",
    "def safe_rate(subset, key):\n",
    "    if not subset:\n",
    "        return 0.0\n",
    "    return sum(1 for r in subset if r[key]) / len(subset)\n",
    "\n",
    "\n",
    "# Key honesty metric: does the model flag DEGRADED when it's actually wrong?\n",
    "degraded_and_wrong_base = [r for r in degraded_rows if not r[\"base_pivot_correct\"]]\n",
    "degraded_and_wrong_ft = [r for r in degraded_rows if not r[\"ft_pivot_correct\"]]\n",
    "\n",
    "\n",
    "def safe_flag_rate(subset, flag_key):\n",
    "    if not subset:\n",
    "        return \"N/A (0 wrong)\"\n",
    "    return f\"{safe_rate(subset, flag_key):.1%} ({sum(1 for r in subset if r[flag_key])}/{len(subset)})\"\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    \"Total examples\": n,\n",
    "    \"Degraded examples\": n_deg,\n",
    "    \"Strong examples\": n_str,\n",
    "    \"\": \"\",\n",
    "    \"--- PIVOT ACCURACY ---\": \"\",\n",
    "    \"Base pivot accuracy (all)\": f\"{safe_rate(rows, 'base_pivot_correct'):.1%}\",\n",
    "    \"FT pivot accuracy (all)\": f\"{safe_rate(rows, 'ft_pivot_correct'):.1%}\",\n",
    "    \"Base pivot accuracy (degraded)\": f\"{safe_rate(degraded_rows, 'base_pivot_correct'):.1%}\",\n",
    "    \"FT pivot accuracy (degraded)\": f\"{safe_rate(degraded_rows, 'ft_pivot_correct'):.1%}\",\n",
    "    \" \": \"\",\n",
    "    \"--- MIRAGE AWARENESS (key metrics) ---\": \"\",\n",
    "    \"Base silent mirage rate\": f\"{safe_rate(degraded_rows, 'base_silent_mirage'):.1%}\",\n",
    "    \"FT silent mirage rate\": f\"{safe_rate(degraded_rows, 'ft_silent_mirage'):.1%}\",\n",
    "    \"Base degradation flag (when degraded)\": f\"{safe_rate(degraded_rows, 'base_flagged_degraded'):.1%}\",\n",
    "    \"FT degradation flag (when degraded)\": f\"{safe_rate(degraded_rows, 'ft_flagged_degraded'):.1%}\",\n",
    "    \"  \": \"\",\n",
    "    \"--- HONESTY (flag when wrong) ---\": \"\",\n",
    "    \"Base flag_given_wrong\": safe_flag_rate(degraded_and_wrong_base, \"base_flagged_degraded\"),\n",
    "    \"FT flag_given_wrong\": safe_flag_rate(degraded_and_wrong_ft, \"ft_flagged_degraded\"),\n",
    "    \"   \": \"\",\n",
    "    \"--- FALSE ALARM RATE ---\": \"\",\n",
    "    \"Base false alarm (flagged when strong)\": f\"{safe_rate(strong_rows, 'base_flagged_degraded'):.1%}\",\n",
    "    \"FT false alarm (flagged when strong)\": f\"{safe_rate(strong_rows, 'ft_flagged_degraded'):.1%}\",\n",
    "    \"    \": \"\",\n",
    "    \"--- FORMAT ADHERENCE ---\": \"\",\n",
    "    \"Base format adherence\": f\"{safe_rate(rows, 'base_format_ok'):.1%}\",\n",
    "    \"FT format adherence\": f\"{safe_rate(rows, 'ft_format_ok'):.1%}\",\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"   MIRAGE-AWARE FINE-TUNING: EVALUATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "for k, v in metrics.items():\n",
    "    if v == \"\":\n",
    "        print(k)\n",
    "    else:\n",
    "        print(f\"  {k:45s} {v}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "base_sr = safe_rate(degraded_rows, \"base_silent_mirage\")\n",
    "ft_sr = safe_rate(degraded_rows, \"ft_silent_mirage\")\n",
    "ft_flag = safe_rate(degraded_rows, \"ft_flagged_degraded\")\n",
    "ft_fa = safe_rate(strong_rows, \"ft_flagged_degraded\")\n",
    "\n",
    "if degraded_and_wrong_ft:\n",
    "    ft_flag_given_wrong = safe_rate(degraded_and_wrong_ft, \"ft_flagged_degraded\")\n",
    "else:\n",
    "    ft_flag_given_wrong = float(\"nan\")\n",
    "\n",
    "print(\"\\nVERDICT:\")\n",
    "if ft_flag > 0.5 and ft_fa < 0.2:\n",
    "    print(f\"  SUCCESS: FT flags {ft_flag:.0%} of degraded cases.\")\n",
    "    print(f\"  False alarm rate: {ft_fa:.0%}\")\n",
    "elif ft_flag > 0.3:\n",
    "    print(f\"  PARTIAL: FT flags {ft_flag:.0%} of degraded cases.\")\n",
    "else:\n",
    "    print(f\"  WEAK: FT only flags {ft_flag:.0%} of degraded cases.\")\n",
    "\n",
    "if degraded_and_wrong_ft:\n",
    "    print(f\"  Honesty (flag|wrong): {ft_flag_given_wrong:.0%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Stratified metrics by difficulty and category\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"   STRATIFIED BY DIFFICULTY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for diff in [\"easy\", \"medium\", \"hard\", \"extreme\"]:\n",
    "    subset = [r for r in rows if r[\"difficulty\"] == diff]\n",
    "    if not subset:\n",
    "        continue\n",
    "    deg_sub = [r for r in subset if r[\"oracle_degraded\"]]\n",
    "    str_sub = [r for r in subset if not r[\"oracle_degraded\"]]\n",
    "\n",
    "    base_acc = safe_rate(subset, \"base_pivot_correct\")\n",
    "    ft_acc = safe_rate(subset, \"ft_pivot_correct\")\n",
    "\n",
    "    ft_flag_deg = safe_rate(deg_sub, \"ft_flagged_degraded\") if deg_sub else 0\n",
    "    ft_silent = safe_rate(deg_sub, \"ft_silent_mirage\") if deg_sub else 0\n",
    "\n",
    "    deg_wrong = [r for r in deg_sub if not r[\"ft_pivot_correct\"]]\n",
    "    fgw = safe_rate(deg_wrong, \"ft_flagged_degraded\") if deg_wrong else float(\"nan\")\n",
    "    fgw_str = f\"{fgw:.1%}\" if deg_wrong else \"N/A\"\n",
    "\n",
    "    print(f\"\\n  {diff.upper()} (n={len(subset)}, {len(deg_sub)} degraded, {len(str_sub)} strong)\")\n",
    "    print(f\"    Pivot acc:        base={base_acc:.1%}  FT={ft_acc:.1%}\")\n",
    "    print(f\"    FT flag (deg):    {ft_flag_deg:.1%}\")\n",
    "    print(f\"    FT silent mirage: {ft_silent:.1%}\")\n",
    "    print(f\"    FT flag|wrong:    {fgw_str} ({len(deg_wrong)} wrong cases)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"   STRATIFIED BY CATEGORY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for cat in [\"investment\", \"incident\", \"narrative\"]:\n",
    "    subset = [r for r in rows if r[\"category\"] == cat]\n",
    "    if not subset:\n",
    "        continue\n",
    "    deg_sub = [r for r in subset if r[\"oracle_degraded\"]]\n",
    "    str_sub = [r for r in subset if not r[\"oracle_degraded\"]]\n",
    "\n",
    "    base_acc = safe_rate(subset, \"base_pivot_correct\")\n",
    "    ft_acc = safe_rate(subset, \"ft_pivot_correct\")\n",
    "    ft_flag_deg = safe_rate(deg_sub, \"ft_flagged_degraded\") if deg_sub else 0\n",
    "    ft_silent = safe_rate(deg_sub, \"ft_silent_mirage\") if deg_sub else 0\n",
    "\n",
    "    deg_wrong = [r for r in deg_sub if not r[\"ft_pivot_correct\"]]\n",
    "    fgw = safe_rate(deg_wrong, \"ft_flagged_degraded\") if deg_wrong else float(\"nan\")\n",
    "    fgw_str = f\"{fgw:.1%}\" if deg_wrong else \"N/A\"\n",
    "\n",
    "    print(f\"\\n  {cat.upper()} (n={len(subset)}, {len(deg_sub)} degraded, {len(str_sub)} strong)\")\n",
    "    print(f\"    Pivot acc:        base={base_acc:.1%}  FT={ft_acc:.1%}\")\n",
    "    print(f\"    FT flag (deg):    {ft_flag_deg:.1%}\")\n",
    "    print(f\"    FT silent mirage: {ft_silent:.1%}\")\n",
    "    print(f\"    FT flag|wrong:    {fgw_str} ({len(deg_wrong)} wrong cases)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print 5 side-by-side examples\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE OUTPUTS (5 examples)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "deg_idx = [i for i, r in enumerate(rows) if r[\"oracle_degraded\"]][:3]\n",
    "str_idx = [i for i, r in enumerate(rows) if not r[\"oracle_degraded\"]][:2]\n",
    "sample_indices = deg_idx + str_idx\n",
    "\n",
    "for idx in sample_indices:\n",
    "    r = rows[idx]\n",
    "    status = \"DEGRADED\" if r[\"oracle_degraded\"] else \"STRONG\"\n",
    "    print(f\"\\n--- Example {idx} ({status}, difficulty={r['difficulty']}, category={r['category']}) ---\")\n",
    "    print(f\"Oracle pivot: {r['oracle_pivot']}\")\n",
    "\n",
    "    print(\"\\nBASE response (first 400 chars):\")\n",
    "    print(base_results[idx][\"response\"][:400])\n",
    "\n",
    "    print(\"\\nFINE-TUNED response (first 400 chars):\")\n",
    "    print(ft_results[idx][\"response\"][:400])\n",
    "\n",
    "    print(f\"\\nBase: pivot={r['base_pivot']}, flagged={r['base_flagged_degraded']}\")\n",
    "    print(f\"FT:   pivot={r['ft_pivot']}, flagged={r['ft_flagged_degraded']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save summary\n",
    "summary_path = \"/content/mirage_aware_eval_summary.json\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "# Package adapter + results for download\n",
    "!cd /content && tar czf mirage_aware_package.tar.gz     mirage_aware_adapter/     mirage_aware_eval_results.csv     mirage_aware_eval_summary.json     base_raw_responses.json     ft_raw_responses.json     training_loss.png\n",
    "\n",
    "print(\"\\nPackage created. Downloading...\")\n",
    "print(\"Contents:\")\n",
    "print(\"  - mirage_aware_adapter/ (LoRA weights)\")\n",
    "print(\"  - mirage_aware_eval_results.csv (per-example results)\")\n",
    "print(\"  - mirage_aware_eval_summary.json (summary metrics)\")\n",
    "print(\"  - base_raw_responses.json / ft_raw_responses.json (raw outputs)\")\n",
    "print(\"  - training_loss.png (loss curve)\")\n",
    "\n",
    "files.download(\"/content/mirage_aware_package.tar.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Done. Check the summary table above for results.\")\n",
    "print(\"\\nKey question: Did the fine-tuned model learn to flag DEGRADED when it is wrong?\")\n",
    "print(f\"  Base silent mirage rate: {base_sr:.1%}\")\n",
    "print(f\"  FT silent mirage rate: {ft_sr:.1%}\")\n",
    "print(f\"  FT degradation detection: {ft_flag:.1%}\")\n",
    "print(f\"  FT false alarm rate: {ft_fa:.1%}\")\n",
    "if degraded_and_wrong_ft:\n",
    "    print(f\"  FT flag_given_wrong: {ft_flag_given_wrong:.1%}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "a792942fd8384c89bb44109f4e5e5031": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_86f2d11e8e7b4487803cdc76a527bff3",
       "IPY_MODEL_3fb0d294e0a14f2191ef293057a2d9b8",
       "IPY_MODEL_e3de2b7d304245b290bf4b2132ec5cab"
      ],
      "layout": "IPY_MODEL_3cea48dbcbe44cd78e126895ba8df9e2"
     }
    },
    "86f2d11e8e7b4487803cdc76a527bff3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d21396b84814aa19816a3cce7fb302e",
      "placeholder": "​",
      "style": "IPY_MODEL_a089bff5819742148cc53153c9b11c61",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "3fb0d294e0a14f2191ef293057a2d9b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca5d1244e7ef4117a740a211adf20bbe",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fa4aa55f0444516b2ef9511356b2673",
      "value": 4
     }
    },
    "e3de2b7d304245b290bf4b2132ec5cab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8030ca9f12da42b7ab3e24c331343618",
      "placeholder": "​",
      "style": "IPY_MODEL_4b342bc0365f4e97952258904015d2ff",
      "value": " 4/4 [00:06&lt;00:00,  1.55s/it]"
     }
    },
    "3cea48dbcbe44cd78e126895ba8df9e2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d21396b84814aa19816a3cce7fb302e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a089bff5819742148cc53153c9b11c61": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca5d1244e7ef4117a740a211adf20bbe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fa4aa55f0444516b2ef9511356b2673": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8030ca9f12da42b7ab3e24c331343618": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b342bc0365f4e97952258904015d2ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0dd6e53d38641bbbea1234ba149e847": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bb9dd55a41e4173a728294eaa48fcfc",
       "IPY_MODEL_18aeede7cf6840f38eeb0862184c6c69",
       "IPY_MODEL_710190d649f2400d80800e2361fe2469"
      ],
      "layout": "IPY_MODEL_241a8ddef6294c268d2ba11cac584cad"
     }
    },
    "8bb9dd55a41e4173a728294eaa48fcfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9a4a0a16ae642c888c8c0725bb08d41",
      "placeholder": "​",
      "style": "IPY_MODEL_8af3a9692fc841acb27080a12aef015e",
      "value": "Map: 100%"
     }
    },
    "18aeede7cf6840f38eeb0862184c6c69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fec9578b1e874288949ddc48beedfaed",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b17c452f52424f0faf3fef18520c4cc1",
      "value": 2000
     }
    },
    "710190d649f2400d80800e2361fe2469": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2634367ef3fd41cc8c1b2e3e1d57da33",
      "placeholder": "​",
      "style": "IPY_MODEL_892f9e1198e947b69be361d2473d40be",
      "value": " 2000/2000 [00:03&lt;00:00, 596.87 examples/s]"
     }
    },
    "241a8ddef6294c268d2ba11cac584cad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9a4a0a16ae642c888c8c0725bb08d41": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8af3a9692fc841acb27080a12aef015e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fec9578b1e874288949ddc48beedfaed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b17c452f52424f0faf3fef18520c4cc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2634367ef3fd41cc8c1b2e3e1d57da33": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "892f9e1198e947b69be361d2473d40be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce7f49a0b94945059f86c1adee217afd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a22b70891b22453e9b63fa10e4cf11e1",
       "IPY_MODEL_f3711d52dc184488a33119dca6ff8639",
       "IPY_MODEL_d14db2339c2e475b84c49c0cf6abe43e"
      ],
      "layout": "IPY_MODEL_a8327a6b3ca34470a536795592fd1c3c"
     }
    },
    "a22b70891b22453e9b63fa10e4cf11e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98ed268efc9c44fdb3629cea36e7de18",
      "placeholder": "​",
      "style": "IPY_MODEL_310d06e9e2364361a1491b116b72a6d7",
      "value": "Map: 100%"
     }
    },
    "f3711d52dc184488a33119dca6ff8639": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_183ae199b5074b90b901c250c28583f6",
      "max": 400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3d9807f9846458da613cd55b615e326",
      "value": 400
     }
    },
    "d14db2339c2e475b84c49c0cf6abe43e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95522b115c044309b5d0a90daf23d0f7",
      "placeholder": "​",
      "style": "IPY_MODEL_97c3927447424d4fa96225ce9cb5bcfa",
      "value": " 400/400 [00:00&lt;00:00, 621.09 examples/s]"
     }
    },
    "a8327a6b3ca34470a536795592fd1c3c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98ed268efc9c44fdb3629cea36e7de18": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "310d06e9e2364361a1491b116b72a6d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "183ae199b5074b90b901c250c28583f6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3d9807f9846458da613cd55b615e326": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "95522b115c044309b5d0a90daf23d0f7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97c3927447424d4fa96225ce9cb5bcfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d8f81eee1e064fd8ab117832893b4e86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff6d7f68aaad4932a87077f9bd7cc478",
       "IPY_MODEL_5dd6b2b2d8054a01bff19495769a5260",
       "IPY_MODEL_edd6d5f097514515a777bc8684132018"
      ],
      "layout": "IPY_MODEL_876fff3e57d44da28f5e7faca548d007"
     }
    },
    "ff6d7f68aaad4932a87077f9bd7cc478": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40379340ad88489fa2ed63e8570781bc",
      "placeholder": "​",
      "style": "IPY_MODEL_ca99a96c7a324754a8a0f00f80b1c953",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "5dd6b2b2d8054a01bff19495769a5260": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a88f91554f3049dc82e778f86c6f706a",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f1115bcf344490c8c860df211db9a62",
      "value": 4
     }
    },
    "edd6d5f097514515a777bc8684132018": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9eba85acdb0a4c5fbf6fc76ba94b45fd",
      "placeholder": "​",
      "style": "IPY_MODEL_5fa218551f09416aa31d0b86652e4297",
      "value": " 4/4 [00:06&lt;00:00,  1.63s/it]"
     }
    },
    "876fff3e57d44da28f5e7faca548d007": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40379340ad88489fa2ed63e8570781bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca99a96c7a324754a8a0f00f80b1c953": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a88f91554f3049dc82e778f86c6f706a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f1115bcf344490c8c860df211db9a62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9eba85acdb0a4c5fbf6fc76ba94b45fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fa218551f09416aa31d0b86652e4297": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f1bccb7a09a48ea839127d270288fdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d69b3af2275148f5a417323db8566e03",
       "IPY_MODEL_51fd0f65eaba42ae82478d525f1061d0",
       "IPY_MODEL_3e574eb7a14546ce825f6cb38680ee23"
      ],
      "layout": "IPY_MODEL_3bf2e4865c0544078ea78ea83faa747c"
     }
    },
    "d69b3af2275148f5a417323db8566e03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9660a7c667d54dfc9adc94c0f2b209b1",
      "placeholder": "​",
      "style": "IPY_MODEL_db1df73f1179425db39b398a252183bc",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "51fd0f65eaba42ae82478d525f1061d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77f789af8b864e7aba4c0e85e7690b38",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b4756ff48fa2434c8e292dd04be936fd",
      "value": 4
     }
    },
    "3e574eb7a14546ce825f6cb38680ee23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a03d5e81e94b4c859b934c449d43e653",
      "placeholder": "​",
      "style": "IPY_MODEL_1c2bca2ffa1c46cd9c9c1ba74d6e1716",
      "value": " 4/4 [00:05&lt;00:00,  1.48s/it]"
     }
    },
    "3bf2e4865c0544078ea78ea83faa747c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9660a7c667d54dfc9adc94c0f2b209b1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db1df73f1179425db39b398a252183bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77f789af8b864e7aba4c0e85e7690b38": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4756ff48fa2434c8e292dd04be936fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a03d5e81e94b4c859b934c449d43e653": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c2bca2ffa1c46cd9c9c1ba74d6e1716": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}